{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7413f18b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Lasy-losowe\" data-toc-modified-id=\"Lasy-losowe-1\">Lasy losowe</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Liczba-estymatorów\" data-toc-modified-id=\"Liczba-estymatorów-1.0.1\">Liczba estymatorów</a></span></li><li><span><a href=\"#Bootstrapping\" data-toc-modified-id=\"Bootstrapping-1.0.2\">Bootstrapping</a></span></li></ul></li><li><span><a href=\"#Trenowanie-pierwszego-modelu-RandomForest-dla-problemu-klasyfikacji\" data-toc-modified-id=\"Trenowanie-pierwszego-modelu-RandomForest-dla-problemu-klasyfikacji-1.1\">Trenowanie pierwszego modelu RandomForest dla problemu klasyfikacji</a></span></li><li><span><a href=\"#Porównianie-lasów-losowych-z-drzewami-decyzyjnymi\" data-toc-modified-id=\"Porównianie-lasów-losowych-z-drzewami-decyzyjnymi-1.2\">Porównianie lasów losowych z drzewami decyzyjnymi</a></span><ul class=\"toc-item\"><li><span><a href=\"#Podobieństwa\" data-toc-modified-id=\"Podobieństwa-1.2.1\">Podobieństwa</a></span></li><li><span><a href=\"#Różnice\" data-toc-modified-id=\"Różnice-1.2.2\">Różnice</a></span></li></ul></li><li><span><a href=\"#Wpływ-parametrów-na-jakość-klasyfikacji\" data-toc-modified-id=\"Wpływ-parametrów-na-jakość-klasyfikacji-1.3\">Wpływ parametrów na jakość klasyfikacji</a></span></li><li><span><a href=\"#Zadanie\" data-toc-modified-id=\"Zadanie-1.4\">Zadanie</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241cbd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris, load_digits, make_circles, make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from mlxtend import plotting\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c09aae",
   "metadata": {},
   "source": [
    "# Lasy losowe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11731dca",
   "metadata": {},
   "source": [
    "Dokumentacja:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5228ddc",
   "metadata": {},
   "source": [
    "Żeby na szybko podejrzeć sygnaturę konstruktora tej klasy wystarczy wpisać poniższą komendę:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53872edb",
   "metadata": {},
   "source": [
    "Warto zwrócić uwagę na podobieństwo do parametrów drzewa decyzyjnego - las losowy to budowa dużej ilości drzew decyzyjnych o takich samych hiperparametrach.\n",
    "\n",
    "```Init signature:\n",
    "ensemble.RandomForestClassifier(\n",
    "    n_estimators='warn',          # ilość drzew, domyślnie 10 lub 100 w zależności od wersji sklearn\n",
    "    criterion='gini',             # miara nieczystości zestawu danych\n",
    "    max_depth=None,               # maksymalna głębokść drzewa\n",
    "    min_samples_split=2,          # minimalna liczba przykładów do podzielenia drzewa\n",
    "    min_samples_leaf=1,           # minimalna liczba próbek w liściu\n",
    "    max_features='auto',          # ile cech jest branę pod uwagę w każdym podziale (w każdym splicie)\n",
    "    max_leaf_nodes=None,          # maksymalna ilość liści - podobne do maksymalnej głębokości\n",
    "    min_impurity_decrease=0.0,    # jakie minimalne ulepszenie nieczystości musimy osiągnąć, by podzielić drzewo\n",
    "    bootstrap=True,               # czy używać bootstrappingu\n",
    "    n_jobs=None,                  # -1 dla zrównoleglania obliczeń na wszystkich rdzeniach procesora\n",
    "    \n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "Większość z tych parametrów, które zostały wymienione, kontroluje ograniczenia nakładane na rozrost drzewa. Pokrywają się one z drzewem decyzyjnym.\n",
    "Najbardziej istotne dla nas są: `n_estimators`, `max_features` oraz `boostrap`.\n",
    "\n",
    "### Liczba estymatorów\n",
    "\n",
    "Ile drzew chcemy budować. Kluczowym jest to, że im więcej drzew, tym więcej wariantów rozwiązania problemu będziemy otrzymywać i tym bardziej \"uśrednione\" będą ostateczne wyniki.\n",
    "\n",
    "### Bootstrapping\n",
    "\n",
    "Bootstrapping to technika losowania podpróbki, która prowadzi otrzymywania różnych drzew. Źródłem skuteczności lasów losowych jest otrzymywanie różnych drzew za każdym razem. Najlepszą techniką jest uzyskiwanie drzew na losowych podzbiorach zbioru uczącego. W ten sposób już na samym początku miary nieczystosci dla każdego podziału będą inne co sprowadzi się do zróżnicowania struktury każdego z drzew.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14475d7a",
   "metadata": {},
   "source": [
    "## Trenowanie pierwszego modelu RandomForest dla problemu klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f24e5d",
   "metadata": {},
   "source": [
    "Jesteśmy już zaznajomieni z treningiem estymatorów w sklearn. Poniższy kod powinien być zrozumiały - różnicą względem innych estymatorów są parametry w konstruktorze i sama nazwa klasy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3366d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(iris['data'], columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dada596",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators = 5, criterion = 'gini', max_depth=4, bootstrap=True, random_state=1)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f59bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f23cf1",
   "metadata": {},
   "source": [
    "Parametrs estimators_ listuje drzewa decyzyjne, które są wykorzystywane w danym ensemblu. Można je zwizualizować jak każde inne drzewo decyzyjne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a074a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea64a9-061b-4e2d-907d-25c6665ae97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75918523",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,12))\n",
    "\n",
    "plot_tree(rf_classifier.estimators_[0],\n",
    "          feature_names=iris.feature_names,\n",
    "          class_names=iris.target_names,\n",
    "         filled=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39373bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,12))\n",
    "plot_tree(rf_classifier.estimators_[1],\n",
    "          feature_names=iris.feature_names,\n",
    "          class_names=iris.target_names,\n",
    "         filled=True,);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eae7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,12))\n",
    "plot_tree(rf_classifier.estimators_[2],\n",
    "          feature_names=iris.feature_names,\n",
    "          class_names=iris.target_names,\n",
    "          filled=True,);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24e33de",
   "metadata": {},
   "source": [
    "Lasy losowe pozwalają na uzyskanie oszacowania istotności każdej ze zmiennych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c73b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rf_classifier.feature_importances_, index=iris.feature_names,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ecdca",
   "metadata": {},
   "source": [
    "## Porównianie lasów losowych z drzewami decyzyjnymi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3720538",
   "metadata": {},
   "source": [
    "### Podobieństwa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4b0bd1",
   "metadata": {},
   "source": [
    "Sklearn zawiera w sobie kilkanaście generatorów do danych syntetycznych, pozwalających wizualizować naturę klasyfikatorów. Skorzystajmy z jednego z nich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602448c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_circles(100, noise=0.1, random_state=0, factor=0.6)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=[\"brg\"[x] for x in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_regions(data, target, classifier, figsize=(15, 8)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plotting.plot_decision_regions(X=data, y=target, clf=classifier, legend=2)\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=[\"brg\"[x] for x in target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=7, bootstrap=True, random_state=1)\n",
    "tree_classifier = DecisionTreeClassifier(criterion='gini', max_depth=7)\n",
    "lr_classifier = LogisticRegression()\n",
    "\n",
    "rf_classifier.fit(X, y)\n",
    "tree_classifier.fit(X, y)\n",
    "lr_classifier.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f949f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_regions(X, y, tree_classifier, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_regions(X, y, rf_classifier, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58528f85",
   "metadata": {},
   "source": [
    "Zarówno lasy jak i drzewa decyzyjne mają podobną, \"kanciastą\" granicę decyzyjną z pewną ilością wysp, próbującą się dopasować możliwie dobrze do zestawu treningowego. Dla porównania - regresja logistyczna nie jest w stanie rozwiązać tego problemu - jest on nieliniowy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3236126",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_regions(X, y, lr_classifier, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1191baef",
   "metadata": {},
   "source": [
    "### Różnice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f472ec49",
   "metadata": {},
   "source": [
    "Skorzystajmy w jeszcze innego zestawu danych - datasetu skanów cyfr. Są to listy składające się z wartości odpowiadającym 8x8 pikseli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b082c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "fig, axes = plt.subplots(1, 10)\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i].imshow(digits.data[i].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211aa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data[1].reshape(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19337d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(digits.data[1].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a697e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e57fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=10, bootstrap=True, random_state=1)\n",
    "tree_classifier = DecisionTreeClassifier(criterion='gini', max_depth=10)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "tree_classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier.score(X_train, y_train), tree_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.score(X_train, y_train), rf_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177bc9eb",
   "metadata": {},
   "source": [
    "## Wpływ parametrów na jakość klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30946252",
   "metadata": {},
   "source": [
    "Prawdziwa zaleta lasów decyzyjnych polega na tym, że pomimo takiej samej złożoności drzewa, modele te są o wiele bardziej zregularyzowane, gdyż rozwiazują problem na wiele więcej sposobów naraz. Różnicę w overfittingu można bardzo łatwo zobaczyć na wykresie poniżej.\n",
    "\n",
    "Jest to wykres dokładności treningowej i testowej w zależności od ilości liści w drzewie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd00413",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_train_scores, rf_train_scores, tree_test_scores, rf_test_scores = [], [], [], []\n",
    "\n",
    "\n",
    "for i in range(2, 125, 1):\n",
    "    tree_classifier = DecisionTreeClassifier(max_leaf_nodes=i).fit(X_train, y_train)\n",
    "    tree_train_scores.append(tree_classifier.score(X_train, y_train))\n",
    "    tree_test_scores.append(tree_classifier.score(X_test, y_test))\n",
    "    \n",
    "    rf_classifier = RandomForestClassifier(n_estimators=50, max_leaf_nodes=i).fit(X_train, y_train)\n",
    "    rf_train_scores.append(rf_classifier.score(X_train, y_train))\n",
    "    rf_test_scores.append(rf_classifier.score(X_test, y_test))\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.xlabel(\"Maksymalna liczba lisci\")\n",
    "plt.ylabel(\"Wynik\")\n",
    "\n",
    "plt.plot(range(2, 125, 1), rf_train_scores, 'm--')\n",
    "plt.plot(range(2, 125, 1), rf_test_scores, 'm')\n",
    "plt.plot(range(2, 125, 1), tree_train_scores, 'b--')\n",
    "plt.plot(range(2, 125, 1), tree_test_scores, 'b');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab06577",
   "metadata": {},
   "source": [
    "W miarę dokładania ilości drzew wynik powinien stopniowo się poprawiać. Co istotne - niezregularyzowane drzewo powinno osiągać prawie idealne wyniki na zestawie treningowym, więc im większy poziom testowy, tym bliżej do wyniku na zbiorze treningowym = model mniej się przeucza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8599fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_test_scores, rf_test_scores = [], [[], [], [], []]\n",
    "\n",
    "estimators_set = [5, 15, 25, 100]\n",
    "\n",
    "for node_cnt in range(5, 100, 5):\n",
    "    tree_classifier = DecisionTreeClassifier(max_leaf_nodes=node_cnt).fit(X_train, y_train)\n",
    "    tree_test_scores.append(tree_classifier.score(X_test, y_test))\n",
    "    \n",
    "    for idx, tree_cnt in enumerate(estimators_set):\n",
    "        rf_classifier = RandomForestClassifier(n_estimators=tree_cnt, max_leaf_nodes=node_cnt).fit(X_train, y_train)\n",
    "        rf_test_scores[idx].append(rf_classifier.score(X_test, y_test))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.plot(range(5, 100, 5), tree_test_scores,label = 'tree')\n",
    "\n",
    "for i in range(4):\n",
    "    plt.plot(range(5, 100, 5), rf_test_scores[i], label=estimators_set[i])\n",
    "_ =plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = []\n",
    "scores_train = []\n",
    "\n",
    "for n_estm in range(1, 100, 2):\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=n_estm, random_state=0).fit(X_train, y_train)\n",
    "    scores_test.append(rf_classifier.score(X_test, y_test))\n",
    "    scores_train.append(rf_classifier.score(X_train, y_train))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.xlabel(\"Liczba estymatorów\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(range(1, 100, 2), scores_test,  'm')\n",
    "plt.plot(range(1, 100, 2), scores_train, 'b');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3463b",
   "metadata": {},
   "source": [
    "## Zadanie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68769a20",
   "metadata": {},
   "source": [
    "Wykreśl zależność między **min_samples_leaf** i **max_depth** a dokładnością na zbiorze testowym.\n",
    "\n",
    "(Analogiczny wykres jak ten z max_leaf_nodes i n_estimators).\n",
    "\n",
    "Użyj poniższego zestawu danych generowanego przez funkcję datasets.make_moons.\n",
    "\n",
    "Do oceny dokładności użyj metody .score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d45d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pobranie danych ##\n",
    "X, y = make_moons(n_samples=500, noise=0.1)\n",
    "\n",
    "## podział na zbiór treningowy i testowy ##\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aca2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_scores = [[], [], [], []]\n",
    "sample_set = [1, 5, 10, 20]\n",
    "\n",
    "for i in range(1, 20, 2):\n",
    "    for ix, n in enumerate(sample_set):\n",
    "        forest = RandomForestClassifier(min_samples_leaf=n, max_depth=i)\n",
    "        forest.fit(X_train, y_train)\n",
    "        rf_test_scores[ix].append(forest.score(X_test, y_test))\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(4):\n",
    "    plt.plot(range(1, 20, 2), rf_test_scores[i], label=sample_set[i])\n",
    "    \n",
    "\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad247a45-99e4-4d31-bb4f-903923cbaf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bbd253-29e8-4981-83c7-76ceee9a3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 12))\n",
    "\n",
    "plot_tree(forest[0], filled=True,);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94085bb-9a6e-43f2-8d69-60c4bc635c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_regions(X_train, y_train, forest[1], figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d7c25-f95a-4693-a107-7403ca9dc8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_regions(X_train, y_train, forest, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ebca53-cb26-43ee-ac5b-80b2c17cbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
