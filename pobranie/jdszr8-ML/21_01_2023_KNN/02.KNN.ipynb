{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Regresja\" data-toc-modified-id=\"Regresja-1\">Regresja</a></span><ul class=\"toc-item\"><li><span><a href=\"#Predykcja-z-domyslnymi-parametrami\" data-toc-modified-id=\"Predykcja-z-domyslnymi-parametrami-1.1\">Predykcja z domyslnymi parametrami</a></span></li><li><span><a href=\"#Zadanie-2.\" data-toc-modified-id=\"Zadanie-2.-1.2\">Zadanie 2.</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.datasets import fetch_california_housing, load_boston\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przyjrzyjmy się prostemu zestawowi danych do klasyfikacji. Mamy cztery zmienne niezależne i trzy klasy, do których dane przypadki możemy zaliczyć. Wszystkie dane mają charakter numeryczny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotujmy dane oraz klasyfikator. Dla ułatwienia wykreślania użyjemy tylko dwóch zmiennych.\n",
    "\n",
    "Zwróć uwagę na element Pipeline, tworzony przez funkcję make_pipeline. Ten obiekt łączy ze sobą kilka róznych estymatorów w jedną całość, na której można używać metod fit i predict. Taka całość pozwala nam dodać normalizację bezpośrednio do samego modelu i przestać myśleć o pośrednich etapach przetwarzania danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neighbors.KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###------------ budowa klasyfikatora knn ---------------------------------\n",
    "n_neighbors = 5\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform', algorithm='auto')\n",
    "\n",
    "##------------- pipeline wraz z normalizacją ---------\n",
    "knn_pipeline = make_pipeline(MinMaxScaler(), knn)    # nowy koncept\n",
    "knn_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline.predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykreślmy jak każdy punkt przestrzeni zostanie przydzielony przez nasz klasyfikator do jednej lub drugiej klasy. Każdy punkt powinien być przydzielony do tej samej klasy, do której trzy najbliższe punkty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-------------- budowa siatki dla wykresu ------------------\n",
    "h = .02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(x_min, x_max, h).shape, np.arange(y_min, y_max, h).shape, 280 * 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.c_[xx.ravel(), yy.ravel()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-----------  predykcja dla całej siatki --------\n",
    "prediction = knn_pipeline.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "prediction = prediction.reshape(xx.shape)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "## ---------------- definicje kolorów (hex) ------\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA','#00AAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00','#004D99'])\n",
    "\n",
    "###------- kolorujemy przestrzen na podstawie siatki ---------\n",
    "plt.pcolormesh(xx, yy, prediction, cmap=cmap_light, shading='auto')\n",
    "\n",
    "##--------- nanosimy punkty -----------------\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolors='black')\n",
    "plt.title(\"3-Class classification (k = {0})\".format( n_neighbors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jakość klasyfikacji możemy ocenić metodami z pakietu `metrics`. Tutaj wykorzystamy miarę dokładności - zwróć uwagę na użycie `.predict()` do otrzymania predykcji z modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y, knn_pipeline.predict(X)) # ocena na zbiorze treningowym - warto dolozyc zbior testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# Plotting Decision Regions\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "fig = plot_decision_regions(X,y,clf=knn_pipeline, legend=2)\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('sepal width [cm]')\n",
    "plt.title('knn on Iris')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotujmy ramkę danych dla zadania regresji, wybierzmy wartość docelową"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "df['y'] = boston['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predykcja z domyslnymi parametrami\n",
    "\n",
    "Dla domyślnego klasyfikatora/regresora ilość sąsiadów jest równa k=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg = KNeighborsRegressor()\n",
    "\n",
    "knn_reg.fit(df.drop(columns=['y']), df['y'])\n",
    "preds = knn_reg.predict(df.drop(columns=['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg.score(df.drop(columns=['y']), df['y']) #R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Błąd średniokwadratowy jest naszą miarą dokładności w przypadku zwykłej regresji. Im mniejszy - tym lepszy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(df['y'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dobierzmy więc optymalną liczbę sąsiadów dla naszego modelu. W tym celu sprawdźmy, jak dla różnych wartości k prezentuje się nasz błąd. Zwrócmy uwagę, że nie wykorzystujemy zbioru treningowego i testowego, więc dla k=1 dokładność będzie perfekcyjna - w praktyce powinniśmy dokonać ewaluacji na osobnym zbiorze.\n",
    "\n",
    "Wykres na zbiorze treningowym ukazuje nam pewną zależność - dodawanie nowych próbek zwieksza nam błąd na zbiorze treningowym. Oznacza to, że dopasowanie do danych spada wraz ze wzrastającym k - jest tak, gdyż im więcej wartości jest uśrednianych, tym bardziej te wartości odstają od średniej tych wartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for k in range(1, 50):\n",
    "    #Narysuj wykres zależności K od RMSE na zbiorze treningowym\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(df.drop(columns=['y']), df['y'])\n",
    "    preds = knn.predict(df.drop(columns=['y']))\n",
    "    scores.append(np.sqrt(mean_squared_error(df['y'], preds)))\n",
    "    \n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('K vs RMSE')\n",
    "plt.plot(range(1,50), scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku ewaluacji na zbiorze testowym zobaczymy zupełnie inną zależności - istnieje optymalne ustawienie k, dla którego dokładność jest największa (tj. błąd jest najmniejszy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['y']),\n",
    "                                                   df['y'],\n",
    "                                                   test_size=.2,\n",
    "                                                   random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = []\n",
    "test_error = []\n",
    "\n",
    "for k in range(1, 10):\n",
    "    # powtórz wykres jak wyżej dla zbioru testowego i treningowego\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    preds = knn.predict(X_train)\n",
    "    train_error.append(np.sqrt(mean_squared_error(y_train, preds)))\n",
    "    \n",
    "    preds2 = knn.predict(X_test)\n",
    "    test_error.append(np.sqrt(mean_squared_error(y_test, preds2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('K vs MSE')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('MSE')\n",
    "plt.plot(range(1,10), train_error, label='train error')\n",
    "plt.plot(range(1,10), test_error, label='test error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2. \n",
    "\n",
    "1. Wyrzucić outliery ze zbioru X_train zaczniemy od usuwania wartości odstających. Metoda IQR - inter-quartile range - określa różnicę między pierwszym i czwartym kwartylem (czyli tytułowe IQR) i traktuje to jako miarę rozciągłości zbioru danych. Wszystkie dane poza 1.5 * IQR od któregokolwiek z kwartyli są wartościami odstającymi,   \n",
    "2. Zestandaryzować / minmaxscaler X_train i X_test (standard scaler i minmax),  \n",
    "3. Porównanie metryk: jakie będą wyniki dla p=1, 2, 10\n",
    "4. Zestandaryzowane zbiory danych wrzucić do pętli powyżej i zbaczyć jak wyglądają train i test mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
