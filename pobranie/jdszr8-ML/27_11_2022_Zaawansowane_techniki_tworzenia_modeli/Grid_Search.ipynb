{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poprawa jakości modelu z Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pts(csv_name):\n",
    "    data = np.asarray(pd.read_csv(csv_name, header=None))\n",
    "    X = data[:,0:2]\n",
    "    y = data[:,2]\n",
    "\n",
    "    plt.scatter(X[np.argwhere(y==0).flatten(),0], X[np.argwhere(y==0).flatten(),1],s = 50, color = 'blue', edgecolor = 'k')\n",
    "    plt.scatter(X[np.argwhere(y==1).flatten(),0], X[np.argwhere(y==1).flatten(),1],s = 50, color = 'red', edgecolor = 'k')\n",
    "    \n",
    "    plt.xlim(-2.05,2.05)\n",
    "    plt.ylim(-2.05,2.05)\n",
    "    plt.grid(False)\n",
    "    plt.tick_params(\n",
    "        axis='x',\n",
    "        which='both',\n",
    "        bottom='off',\n",
    "        top='off')\n",
    "\n",
    "    return X,y\n",
    "\n",
    "X, y = load_pts('data.csv')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Podział trening-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "#Fixing a random seed\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dopasowanie Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the model (with default hyperparameters)\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwiazualizujmy model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(X, y, clf):\n",
    "    plt.scatter(X[np.argwhere(y==0).flatten(),0],X[np.argwhere(y==0).flatten(),1],s = 50, color = 'blue', edgecolor = 'k')\n",
    "    plt.scatter(X[np.argwhere(y==1).flatten(),0],X[np.argwhere(y==1).flatten(),1],s = 50, color = 'red', edgecolor = 'k')\n",
    "\n",
    "    plt.xlim(-2.05,2.05)\n",
    "    plt.ylim(-2.05,2.05)\n",
    "    plt.grid(False)\n",
    "    plt.tick_params(\n",
    "        axis='x',\n",
    "        which='both',\n",
    "        bottom='off',\n",
    "        top='off')\n",
    "\n",
    "    r = np.linspace(-2.1,2.1,300)\n",
    "    s,t = np.meshgrid(r,r)\n",
    "    s = np.reshape(s,(np.size(s),1))\n",
    "    t = np.reshape(t,(np.size(t),1))\n",
    "    h = np.concatenate((s,t),1)\n",
    "\n",
    "    z = clf.predict(h)\n",
    "\n",
    "    s = s.reshape((np.size(r),np.size(r)))\n",
    "    t = t.reshape((np.size(r),np.size(r)))\n",
    "    z = z.reshape((np.size(r),np.size(r)))\n",
    "\n",
    "    plt.contourf(s,t,z,colors = ['blue','red'],alpha = 0.2,levels = range(-1,2))\n",
    "    if len(np.unique(z)) > 1:\n",
    "        plt.contour(s,t,z,colors = 'k', linewidths = 2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(X, y, clf)\n",
    "print('The Training F1 Score is', f1_score(train_predictions, y_train))\n",
    "print('The Testing F1 Score is', f1_score(test_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Łał! Jakieś ciężkie przetrenowanie. Nie tylko patrząc na wykres, ale także patrząc na różnicę między wysokim wynikiem train (1,0) a niskim wynikiem testu (0,7). Zobaczmy, czy możemy znaleźć lepsze hiperparametry, aby ten model działał lepiej. Użyjemy do tego wyszukiwania siatki (Grid Search).\n",
    "\n",
    "### 4. Teraż użyjemy Grid Search, żeby ulepszyć model\n",
    "\n",
    "Tutaj wykonamy następujące kroki:\n",
    "1. Najpierw zdefiniujemy parametry, według których chcemy przeprowadzić Grid Search. Można pobawić się z: `max_depth`, `min_samples_leaf` i `min_samples_split`.\n",
    "2. Utwórzymy scorer dla modelu za pomocą `f1_score`.\n",
    "3. Przeprowadzimy grid search na klasyfikatorze, używając parametrów i scoringu.\n",
    "4. Dopasujemy dane do nowego klasyfikatora.\n",
    "5. Narysujemy model i znajdź f1_score.\n",
    "6. Jeśli model jest niewiele lepszy, warto spróbować zmienić zakresy parametrów i dopasować go ponownie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Create the parameters list you wish to tune.\n",
    "#parameters = {'max_depth':[1, 2, 3, 4],'min_samples_leaf':[1, 2, 3], 'min_samples_split':[2, 3, 4]}\n",
    "parameters = {'max_depth':[2,4,6,8,10],\n",
    "              'min_samples_leaf':[2,4,6,8,10], \n",
    "              'min_samples_split':[2,4,6,8,10]}\n",
    "\n",
    "# Make an scoring object.\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "# Perform grid search on the classifier using 'scorer' as the scoring method.\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring = scorer)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters.\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator.\n",
    "best_clf = grid_fit.best_estimator_\n",
    "print(best_clf)\n",
    "\n",
    "# Fit the new model.\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the new model.\n",
    "best_train_predictions = best_clf.predict(X_train)\n",
    "best_test_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Calculate the f1_score of the new model.\n",
    "print('The training F1 Score is', f1_score(best_train_predictions, y_train))\n",
    "print('The testing F1 Score is', f1_score(best_test_predictions, y_test))\n",
    "\n",
    "# Plot the new model.\n",
    "plot_model(X, y, best_clf)\n",
    "\n",
    "# Let's also explore what parameters ended up being used in the new model.\n",
    "best_clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
