{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Jak-wybrać-lepszy-model?\" data-toc-modified-id=\"Jak-wybrać-lepszy-model?-1\">Jak wybrać lepszy model?</a></span></li><li><span><a href=\"#Metryka-sukcesu\" data-toc-modified-id=\"Metryka-sukcesu-2\">Metryka sukcesu</a></span></li><li><span><a href=\"#Proces-uczenia-maszynowego\" data-toc-modified-id=\"Proces-uczenia-maszynowego-3\">Proces uczenia maszynowego</a></span></li><li><span><a href=\"#Klasyfikacja-na-podstawie-Census-Income-Data-Set\" data-toc-modified-id=\"Klasyfikacja-na-podstawie-Census-Income-Data-Set-4\">Klasyfikacja na podstawie <a href=\"https://archive.ics.uci.edu/ml/datasets/Census+Income\" target=\"_blank\">Census Income Data Set</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Zrozumienie-biznesu\" data-toc-modified-id=\"1.-Zrozumienie-biznesu-4.1\">1. Zrozumienie biznesu</a></span></li><li><span><a href=\"#2.-Zrozumienie-danych-/-EDA\" data-toc-modified-id=\"2.-Zrozumienie-danych-/-EDA-4.2\">2. Zrozumienie danych / <a href=\"https://www.analyticsvidhya.com/blog/2021/04/mastering-exploratory-data-analysiseda-for-data-science-enthusiasts/\" target=\"_blank\">EDA</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-Proste-przekształcenia\" data-toc-modified-id=\"2.1-Proste-przekształcenia-4.2.1\">2.1 Proste przekształcenia</a></span></li></ul></li><li><span><a href=\"#3.-Wybor-metryki-sukcesu-i-walidacji\" data-toc-modified-id=\"3.-Wybor-metryki-sukcesu-i-walidacji-4.3\">3. Wybor metryki sukcesu i walidacji</a></span><ul class=\"toc-item\"><li><span><a href=\"#Metryka-sukcesu\" data-toc-modified-id=\"Metryka-sukcesu-4.3.1\">Metryka sukcesu</a></span></li><li><span><a href=\"#Precision:\" data-toc-modified-id=\"Precision:-4.3.2\">Precision:</a></span></li><li><span><a href=\"#Recall:\" data-toc-modified-id=\"Recall:-4.3.3\">Recall:</a></span></li><li><span><a href=\"#Walidacja\" data-toc-modified-id=\"Walidacja-4.3.4\">Walidacja</a></span></li></ul></li><li><span><a href=\"#4.-Budowa-prostego-modelu\" data-toc-modified-id=\"4.-Budowa-prostego-modelu-4.4\">4. Budowa prostego modelu</a></span><ul class=\"toc-item\"><li><span><a href=\"#sprawdzenie-na-zbiorze-testowym\" data-toc-modified-id=\"sprawdzenie-na-zbiorze-testowym-4.4.1\">sprawdzenie na zbiorze testowym</a></span></li><li><span><a href=\"#confusion-matrix-dla-XGBoost\" data-toc-modified-id=\"confusion-matrix-dla-XGBoost-4.4.2\">confusion matrix dla XGBoost</a></span></li><li><span><a href=\"#sprawdzenie-najważniejszych-cech-dla-modeli-drzewiastych\" data-toc-modified-id=\"sprawdzenie-najważniejszych-cech-dla-modeli-drzewiastych-4.4.3\">sprawdzenie najważniejszych cech dla modeli drzewiastych</a></span></li></ul></li><li><span><a href=\"#5.-Feature-Engineering\" data-toc-modified-id=\"5.-Feature-Engineering-4.5\">5. Feature Engineering</a></span></li><li><span><a href=\"#6.-Wybor-cech\" data-toc-modified-id=\"6.-Wybor-cech-4.6\">6. Wybor cech</a></span></li><li><span><a href=\"#7.-Optimalizacja-modelu\" data-toc-modified-id=\"7.-Optimalizacja-modelu-4.7\">7. Optimalizacja modelu</a></span></li></ul></li><li><span><a href=\"#Przemyślenia-końcowe\" data-toc-modified-id=\"Przemyślenia-końcowe-5\">Przemyślenia końcowe</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOhdkNaZrGK9"
   },
   "source": [
    "# Jak wybrać lepszy model?\n",
    "\n",
    "Znalezienie odpowiedzi na to pytanie wymaga wysiłku 😊\n",
    "\n",
    "W większości wypadków wymaga od nas zrozumienia biznesu. Nawet najlepiej wytrenowany model może wyprodukować niechciane rezultaty, gdy źle określimy cel.\n",
    "\n",
    "Wyobraźmy sobie, że chcemy stworzyć system rekomendacji dla YouTube. Przewidzieć jaki kolejny filmik zostanie odtworzony przez użytkownika.\n",
    "- czy chcemy zmaksymalizować click-through rate?\n",
    "- czy chcemy zmaksymalizować czas oglądania?\n",
    "- czy chcemy zmaksymalizować czas oglądania w sesji?\n",
    "- czy może zwiększyć różnorodność i czas oglądania w sesji?\n",
    "\n",
    "Inny przykład, system rowerów miejskich. Biznesowi zależy na tym, żeby na stanowisku były rowery. Co jest lepsze: brak czy nadmiar rowerów na konkretnej stacji?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IF6u4sgprLRX"
   },
   "source": [
    "# Metryka sukcesu\n",
    "Często dla biznesu metryka sukcesu jest oczywista - zarobić więcej pieniędzy (czy to przez automatyzacje procesu, czy przewidywanie zużycia materiału). Jeśli jest inaczej, to pewnie są to np. organizacje non-profit lub instytucje państwowe, które z założenia mają inne cele. Zrozumienie do czego dąży biznes jest dość proste, przerzucenie tego na metrykę sukcesu w uczeniu maszynowym nie musi.\n",
    "\n",
    "Wracając do przykładu z rowerami miejskimi. Jak zapewne wiecie: [\"*Essentially, all models are wrong, but some are useful.*\"](https://en.wikipedia.org/wiki/George_E._P._Box) Teraz tylko pytanie, jak bardzo i w która stronę. Warto zastanowić się, jak karać nasze modele, w zależności od tego jakie są nasze oczekiwania. Na przykład, w przypadku przewidywania mniejszej ilości rowerów na stacji, kara może rosnąć wykładniczo, a w przypadku zawyżonego wskazywania jedynie liniowo. Dlatego model będzie próbował optymalizować się w ten sposób, żeby zawsze przewidzieć trochę więcej rowerow - bo sumarycznie jego kara będzie mniejsza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS3sb-harLUT"
   },
   "source": [
    "# Proces uczenia maszynowego\n",
    "\n",
    "1. Zrozumieć biznes\n",
    "2. Zrozumieć dane i zmienną docelową\n",
    "3. Wybrać odpowiednią metrykę sukcesu i sposób walidacji modelu (model evaluation)\n",
    "4. Zbudować najprostszy możliwy model\n",
    "5. Użyć bardziej zaawansowanego modelu\n",
    "6. Utworzyć nowe cechy (feature engineering)\n",
    "7. Wybrać najlepszy model (model selection)\n",
    "8. Wybrać najlepsze cechy (feature selection)\n",
    "9. Optymalizacja modelu (np. GridSearch, HyperOpt)\n",
    "10. Uprodukcyjnienie modelu\n",
    "\n",
    "Proces wytwarzania modeli ten jest cykliczny. Nie ma konieczności znajdowania idealnej kombinacji parametrów ze wszystkich możliwych. Lepiej jest najpierw zrobić pierwsze porównanie na prostych modelach, zobaczyć jakie są problemy i potem przejść do dalszego eksperymentowania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShSIAmPurLEZ"
   },
   "source": [
    "# Klasyfikacja na podstawie [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income)\n",
    "*Dane zostaly zmodyfikowane i wyczyszczone.\n",
    "\n",
    "**Features**\n",
    "- `age`: Age\n",
    "- `workclass`: Working Class (Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked)\n",
    "- `education_level`: Level of Education (Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool)\n",
    "- `education-num`: Number of educational years completed\n",
    "- `marital-status`: Marital status (Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse)\n",
    "- `occupation`: Work Occupation (Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces)\n",
    "- `relationship`: Relationship Status (Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried)\n",
    "- `race`: Race (White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black)\n",
    "- `sex`: Sex (Female, Male)\n",
    "- `capital-gain`: Monetary Capital Gains\n",
    "- `capital-loss`: Monetary Capital Losses\n",
    "- `hours-per-week`: Average Hours Per Week Worked\n",
    "- `native-country`: Native Country (United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands)\n",
    "\n",
    "**Target Variable**\n",
    "- `income`: Income Class (<=50K, >50K)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5fgzN-izFk2"
   },
   "source": [
    "## 1. Zrozumienie biznesu\n",
    "\n",
    "W tym wypadku jest to dość proste. Tego typu zadanie będzie pomocne np. dla organizacji non-profit, które polegają na darowiznach. Dokładne określenie dochodu potencjalnego darczyńcy może pomóc określić, czy warto z taka osoba się kontaktować i o jaka pomoc prosić. Tak więc naszym celem jest zbudowanie modelu, który przewidzi czy dana osoba zarabia więcej niż \\$50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mt7uSECJzBAe"
   },
   "source": [
    "## 2. Zrozumienie danych / [EDA](https://www.analyticsvidhya.com/blog/2021/04/mastering-exploratory-data-analysiseda-for-data-science-enthusiasts/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1631731708363,
     "user": {
      "displayName": "Matt",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08572552845328219396"
     },
     "user_tz": -120
    },
    "id": "6KBMNJGCx6XM"
   },
   "outputs": [],
   "source": [
    "# podstawowe importy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "# wizualizacja\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "base_color = sns.color_palette()[0]\n",
    "\n",
    "import scikitplot as skplt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pokazanie wszystkich kolumn i wierszy\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "error",
     "timestamp": 1631731710613,
     "user": {
      "displayName": "Matt",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08572552845328219396"
     },
     "user_tz": -120
    },
    "id": "xmA2RZogpQbW",
    "outputId": "5c2f12be-7a0a-469c-8d3f-fda875fbda00"
   },
   "outputs": [],
   "source": [
    "# wczytanie danych\n",
    "df = pd.read_csv(\"data/census.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EXx_Bl31w_X"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMwAgfsi1xDB"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuUNiyaiyfa6"
   },
   "outputs": [],
   "source": [
    "# sprawdzenie liczby rekordów\n",
    "n_records = df.shape[0]\n",
    "n_greater_50k = df[df[\"income\"] == \">50K\"].shape[0]\n",
    "n_at_most_50k = df[df[\"income\"] == \"<=50K\"].shape[0]\n",
    "greater_percent = float(n_greater_50k)*100/n_records\n",
    "\n",
    "print(f\"Liczba rekordow: {n_records}\")\n",
    "print(f\"Liczba osob z dochodem powyzej $50,000: {n_greater_50k}\")\n",
    "print(f\"Liczba osob z dochodem co najwyzej $50,000: {n_at_most_50k}\")\n",
    "print(f\"% osob zarabiajacych powyzej $50,000: {greater_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V93o5mFn4s55"
   },
   "outputs": [],
   "source": [
    "# funkcja zwracająca cechy numeryczne\n",
    "def get_quant_features(dataframe):\n",
    "    feats = dataframe.select_dtypes([np.number, np.bool]).columns\n",
    "    return list(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCsj_Ljk31fn"
   },
   "outputs": [],
   "source": [
    "# funkcja rysująca histogramy dla numerycznych cechy\n",
    "def draw_histograms(dataframe, variables, n_rows, n_cols):\n",
    "    fig=plt.figure(figsize=(16,10))\n",
    "    for i, var_name in enumerate(variables):\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
    "        dataframe[var_name].hist(bins=20, ax=ax)\n",
    "        ax.set_title(var_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = get_quant_features(df)\n",
    "draw_histograms(df, feats, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?sns.heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89b_i7pj31lA"
   },
   "outputs": [],
   "source": [
    "# sprawdzenie korelacji\n",
    "df['income_cat'] = (df['income'] != '<=50K').astype('int8')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16,8)\n",
    "sns.heatmap(df.corr(method='pearson'), vmax=1., vmin=-1., annot=True, linewidths=.8, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l79wSUDc31ng"
   },
   "outputs": [],
   "source": [
    "# podstawowy przykład jak można dalej eksplorować dane\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.barplot(x='occupation', y=\"income_cat\", hue='race', data=df)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkmnwYkB9Dby"
   },
   "source": [
    "### 2.1 Proste przekształcenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTAskusy-iHR"
   },
   "source": [
    "Element Feature Engineering, ale można wprowadzić już na tym etapie.\n",
    "<br>W przypadku bardzo asymetrycznyego rozkladu danych, praktyką jest [przekształcenie logarytmiczne](https://en.wikipedia.org/wiki/Data_transformation_(statistics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OK0WNBxX89if"
   },
   "outputs": [],
   "source": [
    "skewed_feats = ['capital-gain', 'capital-loss']\n",
    "\n",
    "for feat in skewed_feats:\n",
    "    df[f'{feat}_log'] = np.log1p(df[feat].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UYO1FmX89fZ"
   },
   "outputs": [],
   "source": [
    "feats = get_quant_features(df)\n",
    "draw_histograms(df, feats, 2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuqCu-sbBxTT"
   },
   "source": [
    "One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ov7YJ3L6AyW8"
   },
   "outputs": [],
   "source": [
    "# funkcja zwracająca cechy jakościowe\n",
    "def get_cat_features(dataframe):\n",
    "    feats = dataframe.select_dtypes(np.object).columns\n",
    "    black_list = ['income']\n",
    "    return [x for x in feats if x not in black_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtpJFp4BBNUI"
   },
   "outputs": [],
   "source": [
    "cat_feats = get_cat_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_fuqQie-vtj"
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=cat_feats, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Db5WurgCAZh"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jjz0cbn3Gd7m"
   },
   "source": [
    "## 3. Wybor metryki sukcesu i walidacji\n",
    "### Metryka sukcesu\n",
    "W naszym wypadku zależy nam na ustaleniu, kto zarabia więcej niż \\\\$50k. Jako, że dystrybucja nie jest zbalansowana (ok. 25\\% zarabia więcej niz \\$50k), użycie samego *accuracy* może nie być wystarczające. Dodatkowo, należy zwrócić uwagę, że nie chcemy predykować, że ktoś zarabia ponad \\$50k, gdy rzeczywistość jest inna (nie chcemy przecież spędzać czasu na tych, którzy nie są potencjalnymi darczyńcami). W tym wypadku, możemy użyć [F-beta score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html), która bierze pod uwagę *precision* i *recall*, gdzie możemy ustawić parametr *beta* = 0.5, gdzie większy nacisk jest kładziony na *precision*.\n",
    "\n",
    "### Precision:\n",
    "**tutaj, false positive oznacza człowieka, który nie zarabia 50k, ale został sklasyfikowany jako >50k (zmarnowany wysiłek)**\n",
    "![train_repeat](img/precision.png)\n",
    "\n",
    "\n",
    "### Recall:\n",
    "**tutaj, false negative oznacza człowieka, który zarabia ponad 50k, ale został sklasyfikowany jako <=50k (zmarnowana szansa)**\n",
    "![train_repeat](img/recall.jpeg)\n",
    "\n",
    "\n",
    "<br>Dodatkowe materiały:\n",
    "- https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9\n",
    "- https://machinelearningmastery.com/fbeta-measure-for-machine-learning/\n",
    "\n",
    "### Walidacja\n",
    "Ponieważ dystrybucja nie jest zbalansowana, powinniśmy ostrożnie wybrać metodę walidacji. w Tym wypadku, rozsądnym jest [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), który zachowuje podobną dystrybucje przy dzieleniu danych.\n",
    "\n",
    "<br>Dodatkowe materiały:\n",
    "- https://machinelearningmastery.com/cross-validation-for-imbalanced-classification/\n",
    "- https://towardsdatascience.com/what-is-stratified-cross-validation-in-machine-learning-8844f3e7ae8e\n",
    "- https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJtBBcX5Tzvx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, fbeta_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnT8LTaLTpM6"
   },
   "source": [
    "## 4. Budowa prostego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtXryf8X-vqo"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "random_state=2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4aqXzD3YA_-"
   },
   "outputs": [],
   "source": [
    "# funkcja podobna do powyższej, tylko wyłapujemy cechy, których nie chcemy użyć w modelu\n",
    "\n",
    "black_list = ['income_cat']\n",
    "\n",
    "def get_model_features(dataframe, black_list):\n",
    "    feats = dataframe.select_dtypes([np.number, np.bool]).columns\n",
    "    return [x for x in feats if x not in black_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rP07Ckf6XdPZ"
   },
   "outputs": [],
   "source": [
    "# przypisujemy X i y\n",
    "feats = get_model_features(df, black_list)\n",
    "\n",
    "X = df[feats]\n",
    "y = df['income_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jj5tE5AfXTrF"
   },
   "outputs": [],
   "source": [
    "# dzielimi na train i test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "\n",
    "print(f\"Train samples: {X_train.shape[0]}.\")\n",
    "print(f\"Test samples: {X_test.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syKdYR6Y-v8H"
   },
   "outputs": [],
   "source": [
    "def run_model(model, X, y, cross_val):\n",
    "    \"\"\"\n",
    "    funkcja przeprowadzająca trening na liście modeli\n",
    "\n",
    "    input:\n",
    "            model: model estymatora z pakietu sklearn\n",
    "            X: cechy do przeprowadzenia uczenia\n",
    "            y: target\n",
    "            cross_val: rodzaj walidacji\n",
    "    output/print:\n",
    "            fbeta_res: wynik fbeta na każdy fold / później uśredniony\n",
    "            accuracy_res: wynik accuracy na każdy fold / później uśredniony\n",
    "            cross_val_time: total scoring time dla obu metryk\n",
    "    \"\"\"\n",
    "    model_name = type(model).__name__\n",
    "\n",
    "    fbeta_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "    \n",
    "    start = time()\n",
    "    fbeta_res = cross_val_score(model, X, y, cv=cross_val, scoring=fbeta_scorer)\n",
    "    accuracy_res = cross_val_score(model, X, y, cv=cross_val, scoring='accuracy')\n",
    "    end = time()\n",
    "    cross_val_time = end-start\n",
    "    print(f\"{model_name} fbeta: {np.mean(fbeta_res):.4f}, accuracy: {np.mean(accuracy_res):.4f}, time: {cross_val_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lItjPnPqFiTk"
   },
   "outputs": [],
   "source": [
    "# funkcja rysująca ważność cech\n",
    "def plot_feature_importances(model, feat_list, ax):\n",
    "\n",
    "    model_name = type(model).__name__\n",
    "    skplt.estimators.plot_feature_importances(model, feature_names=df[feat_list].columns,\n",
    "                                            title=f'{model_name} feature importances', ax=ax)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBoPrjry-vwg"
   },
   "outputs": [],
   "source": [
    "# zdefiniowanie walidacji\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "\n",
    "# zdefiniowanie prostych modeli\n",
    "Dummy_model = DummyClassifier(strategy=\"stratified\") \n",
    "LR_model = LogisticRegression()\n",
    "DT_model = DecisionTreeClassifier(random_state=random_state)\n",
    "RF_model = RandomForestClassifier(random_state=random_state)\n",
    "XGB_model = XGBClassifier(eval_metric='error', random_state=random_state)\n",
    "Gaussian_model = GaussianNB()\n",
    "KNN_model = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "# dodanie modeli do listy, po której będziemy iterowali\n",
    "models = [Dummy_model, LR_model, DT_model, RF_model, XGB_model, Gaussian_model, KNN_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxFyPpAp-v2M"
   },
   "outputs": [],
   "source": [
    "# ewaluacja modeli\n",
    "for model in models:\n",
    "    run_model(model, X_train, y_train, skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sprawdzenie na zbiorze testowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit models\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyniki predykcji\n",
    "y_pred_Dummy_model = Dummy_model.predict(X_test)\n",
    "y_pred_LR_model = LR_model.predict(X_test)\n",
    "y_pred_DT_model = DT_model.predict(X_test)\n",
    "y_pred_RF_model = RF_model.predict(X_test)\n",
    "y_pred_XGB_model = XGB_model.predict(X_test)\n",
    "y_pred_Gaussian_model = Gaussian_model.predict(X_test)\n",
    "y_pred_KNN_model = KNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzenie fbeta_score dla każdego modelu między wynikami predykcji\n",
    "# a rzeczywistymi wartościami ze zbioru treningowego\n",
    "fbeta_Dummy = fbeta_score(y_test, y_pred_Dummy_model, beta=0.5)\n",
    "fbeta_LR = fbeta_score(y_test, y_pred_LR_model, beta=0.5)\n",
    "fbeta_DT = fbeta_score(y_test, y_pred_DT_model, beta=0.5)\n",
    "fbeta_RF = fbeta_score(y_test, y_pred_RF_model, beta=0.5)\n",
    "fbeta_XGB = fbeta_score(y_test, y_pred_XGB_model, beta=0.5)\n",
    "fbeta_Gaussian = fbeta_score(y_test, y_pred_Gaussian_model, beta=0.5)\n",
    "fbeta_KNN = fbeta_score(y_test, y_pred_KNN_model, beta=0.5)\n",
    "\n",
    "results = [fbeta_Dummy, fbeta_LR, fbeta_DT, fbeta_RF, fbeta_XGB, fbeta_Gaussian, fbeta_KNN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----Wyniki f-beta na zbiorze testowym-----\")\n",
    "print(\"Dummy f-beta: {:.4f}\".format(fbeta_Dummy))\n",
    "print(\"Logistic Regression f-beta: {:.4f}\".format(fbeta_LR))\n",
    "print(\"Decision Tree f-beta: {:.4f}\".format(fbeta_DT))\n",
    "print(\"RandomForest f-beta: {:.4f}\".format(fbeta_RF))\n",
    "print(\"XGBoost f-beta: {:.4f}\".format(fbeta_XGB))\n",
    "print(\"Gaussian f-beta: {:.4f}\".format(fbeta_Gaussian))\n",
    "print(\"KNN f-beta: {:.4f}\".format(fbeta_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix dla XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred_XGB_model)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()] #flatten() 'splaszcza' matryce\n",
    "\n",
    "labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_names,group_counts)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8,6)})\n",
    "ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "ax.set(xlabel='Predicted', ylabel='Actual');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sprawdzenie najważniejszych cech dla modeli drzewiastych\n",
    "dla modeli zawierajacych [atrybut *feature_importance_*](https://scikit-plot.readthedocs.io/en/stable/estimators.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20,10))\n",
    "for i, model in enumerate(models[2:5]):\n",
    "    ax=fig.add_subplot(2,4,i+1)\n",
    "    plot_feature_importances(model, feats, ax=ax)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJGWqixV-vzW"
   },
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital_total'] = df['capital-gain'] - df['capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lq1fmGX1hhwX"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'capital_total', 'hours-per-week']\n",
    "\n",
    "\n",
    "# tworzymy kopie df, by moc się przełączać w razie potrzeby między normalnymi danymi a zeskalowanymi.\n",
    "minmax_df = df.copy()\n",
    "minmax_df[numerical] = scaler.fit_transform(minmax_df[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZV4reryhhy3"
   },
   "outputs": [],
   "source": [
    "minmax_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJS4h2Vvhh1d"
   },
   "outputs": [],
   "source": [
    "# przypisujemy X i y\n",
    "black_list = ['income_cat', 'capital-gain', 'capital-loss']\n",
    "feats = get_model_features(minmax_df, black_list)\n",
    "\n",
    "X = minmax_df[feats]\n",
    "y = minmax_df['income_cat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bierzemy tylko modele drzewiaste\n",
    "DT_model = DecisionTreeClassifier(random_state=random_state)\n",
    "RF_model = RandomForestClassifier(random_state=random_state)\n",
    "XGB_model = XGBClassifier(eval_metric='error', random_state=random_state)\n",
    "\n",
    "models = [DT_model, RF_model, XGB_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ewaluacja modeli\n",
    "for model in models:\n",
    "    run_model(model, X_train, y_train, skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit models\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20,10))\n",
    "for i, model in enumerate(models):\n",
    "    ax=fig.add_subplot(1,3,i+1)\n",
    "    plot_feature_importances(model, feats, ax=ax)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Wybor cech\n",
    "\n",
    "Może odbyć się ręcznie, drogą prob i błędów (można np. wykorzystać powyższe 'black_list') lub przy pomocy odpowiednich algorytmów, więcej tutaj:\n",
    "- https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "- https://machinelearningmastery.com/rfe-feature-selection-in-python/\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optimalizacja modelu\n",
    "*odpalenie GridSearcha trochę trwa..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': range(60, 220, 40),\n",
    "    'learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "grid_obj = GridSearchCV(estimator=XGB_model, param_grid=parameters, scoring=fbeta_scorer, cv=skf)\n",
    "grid_fit = grid_obj.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "y_pred = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized XGBoost Model: fbeta = {:.4f}\".format(fbeta_XGB))\n",
    "print(\"Optimized XGBoost Model: fbeta = {:.4f}\".format(fbeta_score(y_test, y_pred, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przemyślenia końcowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proces uczenia maszynowego jest dość złożony i cykliczny. Można spędzić godziny (dni/tygodnie) na ulepszaniu i trenowaniu modeli w różnych kombinacjach parametrów i cech, gdzie granicą feature engineering jest granica wyobraźni (np. w powyższych danych - można łączyć cechy white-male-educated, lub married-male-educated).\n",
    "Jednak zgodnie z zasada Pareto, często 20% nakładu czasu i wysiłku odpowiada za 80% osiąganych wyników. Ponadto, należy zadać sobie pytanie, czy warto walczyć o kolejne 0.5%, gdzie Twój czas to przecież koszt. Ten czas można poświęcić na rozwiązywanie innych problemów, które mogą przynieść potencjalne zyski.\n",
    "\n",
    "![train_repeat](img/train_repeat.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMar/yQfuNI0VHfOuMr9t1Z",
   "collapsed_sections": [],
   "name": "Podsumowanie - ML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
