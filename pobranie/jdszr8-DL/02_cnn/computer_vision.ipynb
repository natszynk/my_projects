{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Czym-jest-obraz?\" data-toc-modified-id=\"Czym-jest-obraz?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Czym jest obraz?</a></span><ul class=\"toc-item\"><li><span><a href=\"#wczytywanie-i-wyświetlanie-obrazów\" data-toc-modified-id=\"wczytywanie-i-wyświetlanie-obrazów-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>wczytywanie i wyświetlanie obrazów</a></span></li></ul></li><li><span><a href=\"#Operacje-na-obrazach\" data-toc-modified-id=\"Operacje-na-obrazach-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Operacje na obrazach</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prosta-matematyka\" data-toc-modified-id=\"Prosta-matematyka-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Prosta matematyka</a></span></li><li><span><a href=\"#Filtrowanie\" data-toc-modified-id=\"Filtrowanie-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Filtrowanie</a></span></li><li><span><a href=\"#Zadanie---wycinanka\" data-toc-modified-id=\"Zadanie---wycinanka-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Zadanie - wycinanka</a></span></li></ul></li><li><span><a href=\"#Wstęp-do-konwolucyjnych-sieci-neuronowych\" data-toc-modified-id=\"Wstęp-do-konwolucyjnych-sieci-neuronowych-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Wstęp do konwolucyjnych sieci neuronowych</a></span><ul class=\"toc-item\"><li><span><a href=\"#Architektura:\" data-toc-modified-id=\"Architektura:-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Architektura:</a></span></li><li><span><a href=\"#operacja-konwolucji\" data-toc-modified-id=\"operacja-konwolucji-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>operacja konwolucji</a></span></li><li><span><a href=\"#Operacja-MaxPool\" data-toc-modified-id=\"Operacja-MaxPool-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Operacja MaxPool</a></span></li><li><span><a href=\"#dane---MNIST\" data-toc-modified-id=\"dane---MNIST-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>dane - MNIST</a></span></li><li><span><a href=\"#Budowa-modelu\" data-toc-modified-id=\"Budowa-modelu-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Budowa modelu</a></span></li><li><span><a href=\"#trening-i-test\" data-toc-modified-id=\"trening-i-test-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>trening i test</a></span></li></ul></li><li><span><a href=\"#Budowa-CNN-w-kerasie\" data-toc-modified-id=\"Budowa-CNN-w-kerasie-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Budowa CNN w kerasie</a></span><ul class=\"toc-item\"><li><span><a href=\"#warstwa-konwolucyjna\" data-toc-modified-id=\"warstwa-konwolucyjna-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>warstwa konwolucyjna</a></span></li><li><span><a href=\"#warstwa-maxpool\" data-toc-modified-id=\"warstwa-maxpool-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>warstwa maxpool</a></span></li><li><span><a href=\"#Model-sekwencyjny-sieci-konwolucyjnej\" data-toc-modified-id=\"Model-sekwencyjny-sieci-konwolucyjnej-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Model sekwencyjny sieci konwolucyjnej</a></span></li><li><span><a href=\"#definiujemy-callback\" data-toc-modified-id=\"definiujemy-callback-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>definiujemy callback</a></span></li><li><span><a href=\"#trening\" data-toc-modified-id=\"trening-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>trening</a></span></li><li><span><a href=\"#podejrzenie-widoku-tensorboard'a\" data-toc-modified-id=\"podejrzenie-widoku-tensorboard'a-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>podejrzenie widoku tensorboard'a</a></span></li><li><span><a href=\"#Zadanie---Modny-task\" data-toc-modified-id=\"Zadanie---Modny-task-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Zadanie - Modny task</a></span></li></ul></li><li><span><a href=\"#Transfer-Learning\" data-toc-modified-id=\"Transfer-Learning-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Transfer Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#wczytujemy-zbiór-od-tenosrflow_datasets\" data-toc-modified-id=\"wczytujemy-zbiór-od-tenosrflow_datasets-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>wczytujemy zbiór od tenosrflow_datasets</a></span></li><li><span><a href=\"#sprawdzenie-na-naszej-sieci\" data-toc-modified-id=\"sprawdzenie-na-naszej-sieci-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>sprawdzenie na naszej sieci</a></span></li><li><span><a href=\"#zabieramy-się-za-czyjś-model-:P\" data-toc-modified-id=\"zabieramy-się-za-czyjś-model-:P-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>zabieramy się za czyjś model :P</a></span></li><li><span><a href=\"#Zadanie---VGG16\" data-toc-modified-id=\"Zadanie---VGG16-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Zadanie - VGG16</a></span></li></ul></li><li><span><a href=\"#ResNet\" data-toc-modified-id=\"ResNet-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>ResNet</a></span><ul class=\"toc-item\"><li><span><a href=\"#dane\" data-toc-modified-id=\"dane-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>dane</a></span></li><li><span><a href=\"#budowa-bloków-residual\" data-toc-modified-id=\"budowa-bloków-residual-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>budowa bloków residual</a></span></li><li><span><a href=\"#model\" data-toc-modified-id=\"model-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>model</a></span></li><li><span><a href=\"#definiujemy-callbacki\" data-toc-modified-id=\"definiujemy-callbacki-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>definiujemy callbacki</a></span></li><li><span><a href=\"#Trening-i-walidacja\" data-toc-modified-id=\"Trening-i-walidacja-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Trening i walidacja</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "W poniższym notebooku zajemiemy się dziedziną przetwarzania obrazu.\\\n",
    "Poznamy podstawowe operacje wykonywane na zdjęciach.\\\n",
    "Rozwiązania uczenia głębokiego tworzyć będziemy w tf.keras z wykorzystaniem konwolucyjnych sieci neuronowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import cv2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras import layers\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tylko dla tych co mają zainstalowaną paczkę jupyterthemes\n",
    "# kto nie ma to niech zakomentuje, ponieważ będzie wywalać błąd\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Czym jest obraz?\n",
    "Sprawdzimy z czego składa się obraz.\\\n",
    "Sprawdzimy czym możemy go wczytać.\\\n",
    "\\\n",
    "Pamietacie RGB? \n",
    "\n",
    "RGB (Red Green Blue) należy do jednego z modeli przestrzeni barw, czyli do widma fal elektromagnetycznych należących do zakresu od 380 do 780 nanometrów. Przedział ten jest tzw. światłem widzialnym. Model ten składa się z trzech kolorów – czerwonego (RED), zielonego (GREEN) i niebieskiego (BLUE). Związany jest on także z właściwościami ludzkiego oka, odpowiedzialnego za odbieranie wiązek światła. Właściwości te sprawiają, że oko jest w stanie dostrzec dowolną barwę dzięki wymieszaniu, w odpowiednich proporcjach, trzech ww. wiązek światła.\n",
    "\n",
    "W informatyce istnieje zapis RGB, który jest 24-bitowym zapisem kolorów (odpowiednio po 8 bitów na kolor). Tutaj każda barwa istnieje w postaci składowych o wartości od 0 do 255. Wartość 0 jest kolorem czarnym, a 255 – białym. Kolor taki można obliczyć w następujący sposób:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wczytywanie i wyświetlanie obrazów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytujemy przy pomocy opencv\n",
    "img = cv2.imread(\"data/1.png\")\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kształt zdjęcia\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typ danych pikseli\n",
    "img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyświetlanie w matplotlibie\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wydzielamy kanały z obrazu\n",
    "img_b, img_g, img_r = img[:,:,0], img[:,:,1], img[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podglądamy kanały\n",
    "# zmieniamy pojedynczą mapę kolorów na szarą\n",
    "plt.gray()\n",
    "# tworzymy siatkę trzech zdjęć\n",
    "fig, (ax_r, ax_g, ax_b) = plt.subplots(nrows=1,ncols=3, sharey=True, figsize=(20,10))\n",
    "# wyświetlamy kanały\n",
    "ax_r.imshow(img_r)\n",
    "ax_g.imshow(img_g)\n",
    "ax_b.imshow(img_b)\n",
    "#nazywamy zdjęcia\n",
    "ax_r.set_title(\"red\")\n",
    "ax_g.set_title(\"green\")\n",
    "ax_b.set_title(\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przedstawienie w kolorach\n",
    "# tworzymy siatkę trzech zdjęć\n",
    "fig, (ax_r, ax_g, ax_b) = plt.subplots(nrows=1,ncols=3, sharey=True, figsize=(20,10))\n",
    "# wyświetlamy kanały\n",
    "\n",
    "# puste zdjęcie trójkanałowe\n",
    "img_empt = np.zeros(img.shape, dtype=np.uint8)\n",
    "# uzupełniamy kanał red o wartości wcześniej wycięte\n",
    "img_empt[:,:,0] = img_r\n",
    "# wyświetlamy\n",
    "ax_r.imshow(img_empt)\n",
    "\n",
    "# puste zdjęcie trójkanałowe\n",
    "img_empt = np.zeros(img.shape, dtype=np.uint8)\n",
    "# uzupełniamy kanał green o wartości wcześniej wycięte\n",
    "img_empt[:,:,1] = img_g\n",
    "# wyświetlamy\n",
    "ax_g.imshow(img_empt)\n",
    "\n",
    "# puste zdjęcie trójkanałowe\n",
    "img_empt = np.zeros(img.shape, dtype=np.uint8)\n",
    "# uzupełniamy kanał blue o wartości wcześniej wycięte\n",
    "img_empt[:,:,2] = img_b\n",
    "# wyświetlamy\n",
    "ax_b.imshow(img_empt)\n",
    "\n",
    "#nazywamy zdjęcia\n",
    "ax_r.set_title(\"red\")\n",
    "ax_g.set_title(\"green\")\n",
    "ax_b.set_title(\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzenie obrazu od zera\n",
    "img_fake = np.arange(int(16*16*1), dtype=np.uint8).reshape(16,16,1)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.imshow(img_fake)\n",
    "plt.title(\"pixels values from 0 to 255\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Operacje na obrazach\n",
    "Poznamy podstawowe mechanizmy przetwarzania obrazów.\\\n",
    "Zastosujemy statyczne filtry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prosta matematyka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skoro obrazy są jak macierze to możemy na nich wykonywać operacje matematyczne\n",
    "img_added = img + 20\n",
    "# tworzymy kontenery na obrazy\n",
    "fig, (ax_0, ax_1) = plt.subplots(nrows=1,ncols=2, sharey=True, figsize=(20,10))\n",
    "# wyświetlamy obrazy\n",
    "ax_0.imshow(img)\n",
    "ax_1.imshow(img_added)\n",
    "#nazywamy zdjęcia\n",
    "ax_0.set_title(\"original\")\n",
    "ax_1.set_title(\"added 20\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdźmy czy faktycznie tak jest na liczbach\n",
    "print(f\"Pierwsze 10 pikseli z pierwszego rzędu i pierwszego kanału.\\nOryginał\\n{img[0:10,0,0]}\\nDodane 20\\n{img_added[0:10,0,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wycięcie kawałka obrazu\n",
    "# pobranie wysokości, szerokości i ilości kanałów\n",
    "h,w,c = img.shape\n",
    "# wycięcie środka\n",
    "img_crop = img[\n",
    "    int(h/2):int(3*h/4),\n",
    "    int(w/2):int(3*w/4),\n",
    "    :\n",
    "]\n",
    "# wyświetlenie oryginału i wycinka\n",
    "fig, (ax_0, ax_1) = plt.subplots(nrows=1,ncols=2, figsize=(20,10))\n",
    "# wyświetlamy obrazy\n",
    "ax_0.imshow(img)\n",
    "ax_1.imshow(img_crop)\n",
    "#nazywamy zdjęcia\n",
    "ax_0.set_title(\"original\")\n",
    "ax_1.set_title(\"crop\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram wartości pikseli, słupków tyle, jaka jest dokładność typu, uin8=>256 wartosci\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.hist(img.ravel(),256,[0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrowanie\n",
    "- w klasycznej obróbce obrazu korzystamy z góry ustalonego filtra\n",
    "- za pomocą odpowiednio skonstruowanej macierzy macierzy zmieniamy wartości pikseli na obrazie\\\n",
    "![imageFilter](data/imageFilter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konwersja na skalę szarości\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# wygładzenie z pozostawieniem krawędzi\n",
    "gray_filtered = cv2.bilateralFilter(gray, 7, 50, 50)\n",
    "\n",
    "# zastosowanie filtru typu \"Canny\"\n",
    "edges = cv2.Canny(gray, 60, 120)\n",
    "edges_filtered = cv2.Canny(gray_filtered, 60, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy siatkę trzech zdjęć\n",
    "fig, (ax_0, ax_1, ax_2) = plt.subplots(nrows=1,ncols=3, sharey=True, figsize=(20,10))\n",
    "# wyświetlamy zdjęcia po kolei\n",
    "ax_0.imshow(gray)\n",
    "ax_1.imshow(edges)\n",
    "ax_2.imshow(edges_filtered)\n",
    "#nazywamy zdjęcia\n",
    "ax_0.set_title(\"gray\")\n",
    "ax_1.set_title(\"edges\")\n",
    "ax_2.set_title(\"edges_filtered\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizacja\n",
    "img_normalized = img/255\n",
    "# tworzymy siatkę dwóch zdjęć\n",
    "fig, (ax_0, ax_1) = plt.subplots(nrows=1,ncols=2, sharey=True, figsize=(20,10))\n",
    "# wyświetlamy zdjęcia po kolei\n",
    "ax_0.imshow(img)\n",
    "ax_1.imshow(img_normalized)\n",
    "#nazywamy zdjęcia\n",
    "ax_0.set_title(\"img\")\n",
    "ax_1.set_title(\"img_normalized\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pierwsze 10 pikseli z pierwszego rzędu i pierwszego kanału.\\nOryginał\\n{img[0:10,0,0]}\\Znormalizowane\\n{img_normalized[0:10,0,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie - wycinanka\n",
    "Na podstawie obrazu \"data/3.png\" chcemy stworzyć nową grafikę, która:\n",
    "- powieli ten obraz czterokrotnie, czyli taka macierz 2x2\n",
    "- będzie posiadać czarną ramkę o grubości 30 pikseli\n",
    "- wyczyszczony będzie całkowicie kanał zielony, środkowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Wstęp do konwolucyjnych sieci neuronowych\n",
    "Poznamy składowe warstwy konwolucyjnej.\\\n",
    "Zbudujemy od podstaw sieć konwolucyjną.\\\n",
    "Sprawdzimy jej funkcjonowanie na prostym przykładzie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architektura:\n",
    "- również składa się z wag i biasów\n",
    "- tym razem wagi ułożone są w postać kernela(filtru)\n",
    "- ten sam kernel 'przemieszcza' się po obrazie ekstraktując wartości, które później przyczynią się do minimalziacji błędu\n",
    "![oneConv](data/oneConv.png)\n",
    "- w teorii zadaniem kernela jest rozpoznanie konkretnych kształtów na zdjęciu\n",
    "- kerneli może być w ramach jednej warstwi więcej niż jeden, tworzą wtedy pojedynczy _feature map_\n",
    "![convManyFilters](data/convManyFilters.png)\n",
    "- pojedynczy kernel najczęściej przyjmuje wielkość macierzy 3x3\n",
    "- przy większych sieciach oraz większych zdjęciach wejściowych stosuje się również kernele 5x5, 7x7, itp.\n",
    "- ponadto dodaje się również pooling, która redukuje ilość danych w celu zmniejszenia ilości obliczeń\n",
    "- tak prezentuje się cała sieć konwolucyjna\n",
    "![convCar](data/convCar.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### operacja konwolucji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pojedyncze zdjęcie 1x4x4x1, NHWC\n",
    "# N - ilość zdjęć\n",
    "# H - wysokość jednego zdjęcia\n",
    "# W - szerokość jednego zdjęcia\n",
    "# C - ilość kanałów jednego zdjęcia\n",
    "tmpImg = np.array([\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1]\n",
    "]).reshape(1,4,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtr, tzw. kernel\n",
    "k = np.array([\n",
    "    [1,1],\n",
    "    [1,1]\n",
    "]).reshape(2,2,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamiana wartości na tensory\n",
    "tmpImg_t = tf.constant(tmpImg, dtype=tf.float32)\n",
    "k_t = tf.constant(k, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = tf.nn.conv2d(\n",
    "    input=tmpImg,\n",
    "    filters=k,\n",
    "    strides=[1,1,1,1],\n",
    "    padding=\"VALID\"\n",
    ")\n",
    "print(f\"Prawdziwy shape {conv.numpy().shape}\")\n",
    "print(f\"jak wygląda zdjęcie po konwolucji\\n{conv.numpy().reshape(3,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operacja MaxPool\n",
    "Jest to po prostu wybranie maksymalnej wartości z danego obszaru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpImg = np.arange(16).reshape(4,4)\n",
    "print(f\"Zdjęcie\\n{tmpImg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpImg_t = tf.constant(tmpImg.reshape(1,4,4,1), dtype=tf.float32)\n",
    "mp = tf.nn.max_pool2d(\n",
    "    input=tmpImg_t,\n",
    "    ksize=[1,2,2,1],\n",
    "    strides=[1,2,2,1],\n",
    "    padding=\"VALID\"\n",
    ")\n",
    "print(f\"jak wygląda zdjęcie po maxpool'u\\n{mp.numpy().reshape(2,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dane - MNIST\n",
    "Zadaniem będzie klasyfikacja ręcznie pisanych cyfr.\\\n",
    "Tym razem nie będzie to dataset digits, tylko MNIST, więcej [tutaj](https://en.wikipedia.org/wiki/MNIST_database)\\\n",
    "Zdjęcia o wielkości 28*28, takżę wymiarowość to 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podpięcie się do paczki\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobranie datasetu\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# normalizacja na liczby w zakresie 0-1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformujemy y_test\n",
    "y_test = OneHotEncoder().fit_transform(y_test.reshape(-1,1)).toarray()\n",
    "# podglądamy\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# transformujemy y_train\n",
    "y_train = OneHotEncoder().fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "# podglądamy\n",
    "y_train = y_train.astype(np.float32)\n",
    "\n",
    "print(\"y_test.shape: \", y_test.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zbadamy ile ich jest\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podejżymy sobie któryś\n",
    "n = 1234\n",
    "plt.matshow(x_train[n])\n",
    "print(\"Label: \", np.argmax(y_train[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budowa modelu\n",
    "Stworzymy prostą sieć konwolucyjną.\\\n",
    "Parametry sieci:\n",
    "- wejście wielkości zdjęcia, czyli 28*28\n",
    "- wyjście wielkości 10, tyle mamy klas cyfr\n",
    "- architektura:\n",
    "    - warstwa wejściowa\n",
    "    - dwie warstwy konwolucja + maxpool\n",
    "        - konwolucje zawsze 3x3\n",
    "    - fully connected, czyli ta standardowa, każdy z każdym\n",
    "    - wyjście, również standardowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model konwolucyjnej sieci neuronowej\n",
    "class modelCNN(object):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network\n",
    "    \"\"\"\n",
    "    def __init__(self, outSize, outAct, conv1Num, conv2Num, fcNum, lr, taskType, dropCoef):\n",
    "        \"\"\"\n",
    "        :param outSize: Output size, number neurons in last layer\n",
    "        :param outAct: output layer activation function, could ber also None\n",
    "        :param conv1Num: number of features in first convolutional layer\n",
    "        :param conv2Num: number of features in second convolutional layer\n",
    "        :param fcNum: number of neurons in fully connected layer\n",
    "        :param lr: leraning rate, speed of training, do not put there too much, net could then explode ;)\n",
    "        :param taskType: type of task, \"reg\" for regression or \"class\" for classification\n",
    "        :param dropCoef: coefficient of dropout, how many percent of random neurons are switched off, if 1 we do not use this\n",
    "        \"\"\"\n",
    "        # inicjalizacja learnig rate'u\n",
    "        self.lr = lr\n",
    "        \n",
    "        ######################## Parametry sieci ##############################\n",
    "        # warstwa wejściowa to same wejścia, wszystko leci na ukrytą\n",
    "        \n",
    "        # warstwy konwolucyjne\n",
    "            # 3, 3 oznacza wielkość macierzy kernela, czyli 3*3\n",
    "            # 1, conv1Num oznacza ilość cech na wejściu i wyjściu warstwy konwolucyjnej\n",
    "        self.W_conv1 = tf.Variable(tf.random.normal([3, 3, 1, conv1Num]))\n",
    "            # biasów jest tyle ile cech wyjściowych z warstwy, czyli conv1Num\n",
    "        self.b_conv1 = tf.Variable(tf.random.normal([conv1Num]))\n",
    "            # druga warstwa konwolucyjna\n",
    "        self.W_conv2 = tf.Variable(tf.random.normal([3, 3, conv1Num, conv2Num]))\n",
    "        self.b_conv2 = tf.Variable(tf.random.normal([conv2Num]))\n",
    "        \n",
    "        # warstwa fully connected, czyli standardowa\n",
    "            # wagi, wielkość wejściowa taka ile mamy cech na ostatniej konwolucji razy wielkość cech po dwóch maxpool'ach\n",
    "        self.W_fc = tf.Variable(tf.random.normal([7*7*conv2Num,fcNum]))\n",
    "            # biasów standardowo tyle ile neuronów\n",
    "        self.b_fc = tf.Variable(tf.zeros([fcNum]))\n",
    "        \n",
    "        # warstwa wyjściowa, 1 neuron z 10 wejściami\n",
    "        self.W_out = tf.Variable(tf.random.normal([fcNum,outSize]))\n",
    "        self.b_out = tf.Variable(tf.zeros([outSize]))\n",
    "\n",
    "        # aktywacje zapamiętujemy na później\n",
    "        self.outAct = outAct\n",
    "        \n",
    "        ###########################################################################\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = tf.optimizers.Adam(self.lr)\n",
    "        \n",
    "        # task type, regression or classification\n",
    "        self.taskType = taskType\n",
    "        \n",
    "        # współczynnik dropout\n",
    "        self.dropCoef = dropCoef\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # feed forward\n",
    "        # wejściowa warstwa, zmieniamy kształt pod konwolucje, standard NHWC, ilość zdjęć * wysokość zdjęcia * szerokość zdjęcia * kanały\n",
    "        layer_in = tf.reshape(x, (-1, 28, 28, 1))\n",
    "        \n",
    "        # pierwsza warstwa konwolucyjna\n",
    "            # konwolucja\n",
    "            # strides oznacza przesuwanie kernela w każdym wymiarze, chcemy o 1 we wszystkich\n",
    "        layer_conv1 = tf.nn.conv2d(layer_in, self.W_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        # po konwolucji otrzymujemy obraz o rozmiarze 28*28*ilość cech\n",
    "            # dodanie biasów\n",
    "        layer_conv1 = tf.nn.bias_add(layer_conv1, self.b_conv1)\n",
    "            # aktywacja\n",
    "        layer_conv1 = tf.nn.relu(layer_conv1)\n",
    "            # maxpool, zmniejszamy obraz o połowę, czyli na 14*14\n",
    "            # ksize oznacz wielkość okna maxpool'a\n",
    "            # strides oznacza o ile będzie się to okno przesuwało w każdym wymiarze\n",
    "        layer_conv1 = tf.nn.max_pool2d(layer_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        # po tym otrzymujemy zdjęcie 14*14*ilość cech\n",
    "        \n",
    "        # pierwsza warstwa konwolucyjna\n",
    "            # konwolucja\n",
    "        layer_conv2 = tf.nn.conv2d(layer_conv1, self.W_conv2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            # dodanie biasów\n",
    "        layer_conv2 = tf.nn.bias_add(layer_conv2, self.b_conv2)\n",
    "            # aktywacja\n",
    "        layer_conv2 = tf.nn.relu(layer_conv2)\n",
    "            # maxpool, zmniejszamy obraz o połowę, czyli na 7*7\n",
    "        layer_conv2 = tf.nn.max_pool2d(layer_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        # aby pójść dalej musimy cechy spłaszczyć do wektora wartości, shape=[nieznana ilość zdjęć, ilość neuronów w fc]\n",
    "        layer_flatten = tf.reshape(layer_conv2, [-1, self.W_fc.get_shape().as_list()[0]])\n",
    "        \n",
    "        # warstwa fully connected\n",
    "            # mnożymy przez wagi i dodajemy biasy\n",
    "        layer_fc = tf.add(tf.matmul(layer_flatten, self.W_fc), self.b_fc)\n",
    "            # przechodzimy z sygnałem przez funkcję aktywacji\n",
    "        layer_fc = tf.nn.relu(layer_fc)\n",
    "            # dropout, wyłączamy losową część neuronów, o ile mniejsze od 1\n",
    "        if self.dropCoef < 1.0:\n",
    "            layer_fc = tf.nn.dropout(layer_fc, self.dropCoef)\n",
    "        \n",
    "        # warstwa wyjściowa\n",
    "            # mnożymy przez wagi i dodajemy biasy\n",
    "        layer_out = tf.add(tf.matmul(layer_fc, self.W_out), self.b_out)\n",
    "            # przechodzimy z sygnałem przez funkcję aktywacji\n",
    "            # rodzaj funkcji aktywacji zależy od parametru podczas tworzenia modelu\n",
    "        if self.outAct != None:\n",
    "            layer_out = self.outAct(layer_out)\n",
    "        return layer_out\n",
    "    \n",
    "    def lossFun(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        :param y_pred: predicted data, from model\n",
    "        :param y_true: true output from model\n",
    "        \"\"\"\n",
    "        # zmiana kztałtu referencji na potrzeby oblcizeń macierzowych\n",
    "        y_true = tf.reshape(y_true, (-1, self.b_out.shape[0]))\n",
    "        if self.taskType == \"class\":\n",
    "            return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_true, y_pred))\n",
    "        elif self.taskType == \"reg\":\n",
    "            return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "        else:\n",
    "            print(\"Error: Task type is not specified. Please set taskType to 'reg' or 'class'\")\n",
    "    \n",
    "    def fit(self, x, y_true):\n",
    "        \"\"\"\n",
    "        :param x: trainin data\n",
    "        :param y_true: connected to x, real output\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as t:\n",
    "            current_loss = self.lossFun(self.predict(x), y_true)\n",
    "        gradients = t.gradient(current_loss, [self.W_conv1, self.b_conv1, self.W_conv2, self.b_conv2, self.W_fc, self.b_fc, self.W_out, self.b_out])\n",
    "        self.optimizer.apply_gradients(zip(gradients, [self.W_conv1, self.b_conv1, self.W_conv2, self.b_conv2, self.W_fc, self.b_fc, self.W_out, self.b_out]))\n",
    "        # błąd zwracamy do świata zewnętrznego|\n",
    "        return current_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trening i test\n",
    "- z uwagi na ogromną ilość danych uczyć będziemy paczkami (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametry modelu\n",
    "# wielkość wyjścia\n",
    "_outSize = 10\n",
    "# aktywacja wyjścia\n",
    "_outAct = None#tf.nn.relu\n",
    "# ilość cech w pierwszej warstwie konwolucyjnej\n",
    "_conv1Num = 8\n",
    "# ilość cech w drugiej warstwie konwolucyjnej\n",
    "_conv2Num = 16\n",
    "# ilość neuronów w warstwie fully connected\n",
    "_fcNum = 200\n",
    "# współczynnik uczenia, mały -> wolno, duży -> szybko\n",
    "_lr = 0.01\n",
    "\n",
    "# utworzenie nie nauczonego modelu\n",
    "myCNN = modelCNN(_outSize, _outAct, _conv1Num, _conv2Num, _fcNum, _lr, \"class\", 1)\n",
    "\n",
    "# czysta lista na błąd\n",
    "lossList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lecimy po epokach i trenujemy na całym zbiorze treningowym\n",
    "epochNum = 10\n",
    "batchSize = 200\n",
    "batchNum = int(x_train.shape[0]/batchSize)\n",
    "lastBatch = x_train.shape[0]%batchSize\n",
    "if lastBatch>0:\n",
    "    batchNum += 1\n",
    "for e in range(epochNum):\n",
    "    # lista błędów w ramach jednej epoki\n",
    "    tmpLossList = []\n",
    "    # bierzemy kawałki datasetu\n",
    "    for i in range(batchNum):\n",
    "        batchStart = i*batchSize\n",
    "        batchEnd = batchStart+batchSize\n",
    "        if lastBatch>0 and i == batchNum-1:\n",
    "            batchEnd = batchStart+lastBatch\n",
    "        tmpLossList.append(myCNN.fit(x_train[batchStart:batchEnd], y_train[batchStart:batchEnd]).numpy())\n",
    "    \n",
    "    # średni błąd z wszystkich batchy wpisujemy na listę\n",
    "    lossMean = np.array(tmpLossList).mean()\n",
    "    lossList.append(lossMean)\n",
    "    print(\"epoch {0}, loss {1}\".format(e, lossMean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zebrane błędy wyświetlamy\n",
    "print(\"Wyjścia po treningu {0} epok:\\n{1}\\n\\nReferencyjne wyjścia:\\n{2}\".format(\n",
    "    epochNum, \n",
    "    tf.nn.softmax(myCNN.predict(x_test[:5])).numpy().argmax(axis=1), \n",
    "    y_test[:5].argmax(axis=1)))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(lossList)\n",
    "plt.show()\n",
    "\n",
    "# testowanie\n",
    "y_pred = tf.nn.softmax(myCNN.predict(x_test)).numpy()\n",
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Budowa CNN w kerasie\n",
    "Skonstruujemy konwolucyjną sieć neuronową w wysokopoziomowych API tf.keras.\\\n",
    "Wykorzystamy model do prostego zadania klasyfikacji.\\\n",
    "Poznamy nowe metryki w klasyfikacji poprzez zastosowanie callbacków."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### warstwa konwolucyjna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = layers.Conv2D(\n",
    "    filters=1,\n",
    "    kernel_size=2,\n",
    "    strides=2,\n",
    "    padding=\"VALID\",\n",
    "    activation=\"relu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpImg = np.array([\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1]\n",
    "], dtype=np.float32).reshape(1,4,4,1)\n",
    "conv(tmpImg).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### warstwa maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definicja warstwy\n",
    "mp = layers.MaxPool2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=2,\n",
    "    padding=\"VALID\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jak wygląda wyjście\n",
    "tmpImg = np.array([\n",
    "    [1,1,1,1],\n",
    "    [4,1,1,8],\n",
    "    [1,1,3,1],\n",
    "    [2,1,1,1]\n",
    "], dtype=np.float32).reshape(1,4,4,1)\n",
    "mp(tmpImg).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model sekwencyjny sieci konwolucyjnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(inShape, convNum, hNum, hAct, outNum, loss):\n",
    "    \"\"\"\n",
    "    :param inShape: kształt wejścia, h*w*c\n",
    "    :param convNum: lista ilości featerów w warstwach konwolucyjnych\n",
    "    :param hNum: lista ilości neuronów w poszczególnych warstwach ukrytych\n",
    "    :param hAct: rodzaj aktywacji w warstwach ukrytych, str\n",
    "    :param outNum: ilość\n",
    "    :param loss: funkcja kosztu\n",
    "    \"\"\"\n",
    "    # pusty model\n",
    "    model = tf.keras.Sequential()\n",
    "    # warstwa wejściowa\n",
    "    model.add(layers.InputLayer(input_shape=(inShape)))\n",
    "    # warstwy konwolucyjne\n",
    "    for idx, oneConvNum in enumerate(convNum):\n",
    "        # dodajemy kolejną warstwę konwolucyjną\n",
    "        # zmienia nam ilość cech(kanałów) na oneConvNum\n",
    "        model.add(layers.Conv2D(\n",
    "                                    filters=oneConvNum,\n",
    "                                    kernel_size=3,\n",
    "                                    strides=1,\n",
    "                                    padding=\"SAME\",\n",
    "                                    activation=\"relu\"\n",
    "                                    )\n",
    "                                )\n",
    "        # doajemy następującego po convie maxpool'a\n",
    "        # zmniejsza nam wymiarowość HxW o połowę\n",
    "        model.add(layers.MaxPool2D(\n",
    "                                    pool_size=(2, 2),\n",
    "                                    strides=2,\n",
    "                                    padding=\"SAME\"\n",
    "                                    )\n",
    "                                )\n",
    "    # spłaszczamy po konwolucjach, przygotowanie pod relu\n",
    "    model.add(layers.Flatten())\n",
    "    # warstwy fully connected\n",
    "    for idx, oneHidNum in enumerate(hNum):\n",
    "        # dodajemy warstwę\n",
    "        model.add(layers.Dense(oneHidNum, activation=hAct))\n",
    "    # warstwa wyjściowa\n",
    "    model.add(layers.Dense(outNum))\n",
    "    # warstwa softmax, dystrybucja prawdopodobieństwa\n",
    "    model.add(layers.Softmax())\n",
    "    print(model.summary())\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=loss,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmieniamy shape pod konwolucje\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "x_train = x_train.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN = create_cnn_model(\n",
    "    inShape=x_train.shape[1:],\n",
    "    convNum=[8,16],\n",
    "    hNum=[200],\n",
    "    hAct=\"relu\",\n",
    "    outNum=10,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definiujemy callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodajemy zapisywanie logów do tensorboard'a\n",
    "log_dir = \"logs\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = modelCNN.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=200,\n",
    "    epochs=10,\n",
    "    validation_split=0.05,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jakie wartości przechowuje historia wyników\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2,ncols=2, figsize=(20,10))\n",
    "# wyświetlamy wykresy\n",
    "ax[0][0].plot(history.history[\"loss\"])\n",
    "ax[0][1].plot(history.history[\"accuracy\"])\n",
    "ax[1][0].plot(history.history[\"val_loss\"])\n",
    "ax[1][1].plot(history.history[\"val_accuracy\"])\n",
    "#nazywamy zdjęcia\n",
    "ax[0][0].set_title(\"train loss\")\n",
    "ax[0][1].set_title(\"train accuracy\")\n",
    "ax[1][0].set_title(\"validation loss\")\n",
    "ax[1][1].set_title(\"validation accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# testowanie\n",
    "y_pred = modelCNN.predict(x_test)\n",
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### podejrzenie widoku tensorboard'a\n",
    "1. Wewnątrz jupyter notebook'a\\\n",
    "```%load_ext tensorboard\n",
    "%tensorboard --logdir \"logs\"```\n",
    "2. Uruchomienie serwera, jeżeli z poziomu notebooka nie działa, to należy uruchomić z cmd\\\n",
    "```tensorboard --logdir \"logs\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie - Modny task\n",
    "Przeprowadzić klasyfikację ubrań ze zbioru ```tf.keras.datasets.fashion_mnist.load_data()```\n",
    "- wczytać dane\n",
    "- sprawdzić dystrybucję klas w zbiorze, czyli ile jest z każdej z nich\n",
    "- stworzyć model wedle upodobania\n",
    "- trening\n",
    "- test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Transfer Learning\n",
    "Zapoznamy się z mechanizmem transfer learningu wykorzystując złożone modele do trudniejszych zadań."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wczytujemy zbiór od tenosrflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "ds_train, ds_info = tfds.load('horses_or_humans', split='train', shuffle_files=True, with_info=True, as_supervised=True)\n",
    "ds_test = tfds.load('horses_or_humans', split='test', shuffle_files=True, as_supervised=True)\n",
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.show_examples(ds_train, ds_info)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konwertujemy zbiory do zalecanego przez model shape'a\n",
    "batch_size = 256\n",
    "input_shape = (224,224,3)\n",
    "\n",
    "resize_normalize = lambda x, y: (tf.image.resize(tf.cast(x, tf.float32), input_shape[:2])/255.0, y)\n",
    "\n",
    "ds_train_batches = ds_train.map(resize_normalize).cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "ds_test_batches = ds_test.map(resize_normalize).cache().batch(batch_size).prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sprawdzenie na naszej sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN = create_cnn_model(\n",
    "    inShape=input_shape,\n",
    "    convNum=[8,16,24,32,40],\n",
    "    hNum=[200],\n",
    "    hAct=\"relu\",\n",
    "    outNum=2,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trening z podaniem callbacków\n",
    "history = modelCNN.fit(\n",
    "    ds_train_batches,\n",
    "    epochs=10,\n",
    "    validation_data=ds_test_batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2,ncols=2, figsize=(20,10))\n",
    "# wyświetlamy wykresy\n",
    "ax[0][0].plot(history.history[\"loss\"])\n",
    "ax[0][1].plot(history.history[\"accuracy\"])\n",
    "ax[1][0].plot(history.history[\"val_loss\"])\n",
    "ax[1][1].plot(history.history[\"val_accuracy\"])\n",
    "#nazywamy zdjęcia\n",
    "ax[0][0].set_title(\"train loss\")\n",
    "ax[0][1].set_title(\"train accuracy\")\n",
    "ax[1][0].set_title(\"validation loss\")\n",
    "ax[1][1].set_title(\"validation accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testowanie\n",
    "y_pred = modelCNN.predict(ds_test_batches)\n",
    "# wyciąganie z datasetu samych labelek\n",
    "y_test = np.concatenate([y for x, y in ds_test_batches], axis=0).reshape(-1,1)\n",
    "print(classification_report(y_test, np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zabieramy się za czyjś model :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wejście\n",
    "inputLayer = tf.keras.Input(shape=(input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bierzemy wytrenowany wcześniej model\n",
    "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    weights='imagenet',  # wczytaj z nauczonymi wagami\n",
    "    input_shape=input_shape,\n",
    "    include_top=False)   # nie dołączaj ostatniej warstwy klasyfikatora, sami swoją dodamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nie chcemy aby nauczony już feature extractor się uczył\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodajemy ostatnie warstwy klasyfikatora\n",
    "x = base_model(inputLayer, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "output = layers.Dense(2, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamykamy w kerasowy model\n",
    "model = tf.keras.Model(inputLayer, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kompilujemy całość\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trening z podaniem callbacków\n",
    "history = model.fit(\n",
    "    ds_train_batches,\n",
    "    epochs=10,\n",
    "    validation_data=ds_test_batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2,ncols=2, figsize=(20,10))\n",
    "# wyświetlamy wykresy\n",
    "ax[0][0].plot(history.history[\"loss\"])\n",
    "ax[0][1].plot(history.history[\"accuracy\"])\n",
    "ax[1][0].plot(history.history[\"val_loss\"])\n",
    "ax[1][1].plot(history.history[\"val_accuracy\"])\n",
    "#nazywamy zdjęcia\n",
    "ax[0][0].set_title(\"train loss\")\n",
    "ax[0][1].set_title(\"train accuracy\")\n",
    "ax[1][0].set_title(\"validation loss\")\n",
    "ax[1][1].set_title(\"validation accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testowanie\n",
    "y_pred = model.predict(ds_test_batches)\n",
    "# wyciąganie z datasetu samych labelek\n",
    "y_test = np.concatenate([y for x, y in ds_test_batches], axis=0).reshape(-1,1)\n",
    "print(classification_report(y_test, np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie - VGG16\n",
    "Należy zapożyczyć pretrenowany model VGG16, dopasować do wczytanego zbioru oraz wyniki porównać z modelem mobilenet.\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "Sieć konwolucyjna składająca się z tzw. bloków rezydualnych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobranie danych\n",
    "ds_train, ds_info = tfds.load('cifar10', split='train', shuffle_files=True, with_info=True, as_supervised=True)\n",
    "ds_test = tfds.load('cifar10', split='test', shuffle_files=True, as_supervised=True)\n",
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.show_examples(ds_train, ds_info)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konwertujemy zbiory do zalecanego przez model shape'a\n",
    "batch_size = 256\n",
    "input_shape = (32,32,3)\n",
    "\n",
    "resize_normalize = lambda x, y: (tf.image.resize(tf.cast(x, tf.float32), input_shape[:2])/255.0, tf.one_hot(y, 10))\n",
    "\n",
    "ds_train_batches = ds_train.map(resize_normalize).cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "ds_test_batches = ds_test.map(resize_normalize).cache().batch(batch_size).prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### budowa bloków residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definicja bloku resnet, zapożyczone z notebook'a '2_Residual_blocks'\n",
    "def res_block(input, filters):\n",
    "    x_1 = keras.layers.Conv2D(filters=filters, kernel_size = (3,3), padding = 'same')(input)\n",
    "    x_1 = keras.layers.ReLU()(x_1)\n",
    "    x_1 = keras.layers.BatchNormalization()(x_1)\n",
    "\n",
    "    x_2 = keras.layers.Conv2D(filters=filters, kernel_size = (3,3), padding = 'same')(x_1)\n",
    "\n",
    "    output = keras.layers.Add()([input, x_2])\n",
    "    output = keras.layers.ReLU()(output)\n",
    "    output = keras.layers.BatchNormalization()(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prezentacja bloku resnet\n",
    "input = keras.layers.Input(shape = (160,160,64))\n",
    "dummy_res_block_model = keras.models.Model(inputs = input, outputs = res_block(input))\n",
    "dummy_res_block_model.summary()\n",
    "keras.utils.plot_model(dummy_res_block_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definicja bloku resnet, zapożyczone z notebook'a '2_Residual_blocks'\n",
    "def res_block_downsample(input, filters):\n",
    "    x_1 = keras.layers.Conv2D(filters=filters, kernel_size = (3,3), strides=(2,2), padding = 'same')(input)\n",
    "    x_1 = keras.layers.ReLU()(x_1)\n",
    "    x_1 = keras.layers.BatchNormalization()(x_1)\n",
    "\n",
    "    x_2 = keras.layers.Conv2D(filters=filters, kernel_size = (3,3), padding = 'same')(x_1)\n",
    "\n",
    "    input_downsample = keras.layers.Conv2D(filters=filters, kernel_size = (1,1), strides=(2,2) ,padding = 'same')(input)\n",
    "    \n",
    "    output = keras.layers.Add()([input_downsample, x_2])\n",
    "    output = keras.layers.ReLU()(output)\n",
    "    output = keras.layers.BatchNormalization()(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prezentacja bloku resnet downsample\n",
    "input = keras.layers.Input(shape = (160,160,64))\n",
    "dummy_res_block_downsample_model = keras.models.Model(inputs = input, outputs = res_block_downsample(input))\n",
    "dummy_res_block_downsample_model.summary()\n",
    "keras.utils.plot_model(dummy_res_block_downsample_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.Input(shape=(32,32,3), dtype = tf.float32)\n",
    "\n",
    "bn_0 = keras.layers.BatchNormalization()(input_layer)\n",
    "conv_0 = keras.layers.Conv2D(filters=8, kernel_size = (3,3), strides=(1,1), padding = 'same')(bn_0)\n",
    "relu = keras.layers.ReLU()(conv_0)\n",
    "bn_1 = keras.layers.BatchNormalization()(relu)\n",
    "\n",
    "resblock_1 = res_block(bn_1, 8)\n",
    "resblock_2 = res_block(resblock_1, 8)\n",
    "resblock_3 = res_block(resblock_2, 8)\n",
    "resblock_4 = res_block_downsample(resblock_3, 16)\n",
    "\n",
    "resblock_5 = res_block(resblock_4, 16)\n",
    "resblock_6 = res_block(resblock_5, 16)\n",
    "resblock_7 = res_block(resblock_6, 16)\n",
    "resblock_8 = res_block_downsample(resblock_7, 32)\n",
    "\n",
    "resblock_9 = res_block(resblock_8, 32)\n",
    "resblock_10 = res_block(resblock_9, 32)\n",
    "resblock_11 = res_block(resblock_10, 32)\n",
    "resblock_12 = res_block_downsample(resblock_11, 64)\n",
    "\n",
    "avg_pool = keras.layers.GlobalAveragePooling2D()(resblock_12)\n",
    "#flat = keras.layers.Flatten()(resblock_12)\n",
    "dropout = keras.layers.Dropout(0.7)(avg_pool)\n",
    "out = keras.layers.Dense(10)(dropout)\n",
    "out = keras.layers.Softmax()(out)\n",
    "\n",
    "model_small_resnet = tf.keras.Model(\n",
    "    inputs=input_layer,\n",
    "    outputs=out,\n",
    "    name=\"small_resnet\"\n",
    ")\n",
    "\n",
    "model_small_resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definiujemy callbacki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodajemy zapisywanie logów do tensorboard'a\n",
    "log_dir = \"logs\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback od wcześniejszego zakończenia treningu\n",
    "patience = 4\n",
    "es_callback = keras.callbacks.EarlyStopping(patience=patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening i walidacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small_resnet.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small_resnet.fit(\n",
    "    ds_train_batches,\n",
    "    validation_data=ds_test_batches,\n",
    "    callbacks=[\n",
    "        tensorboard_callback,\n",
    "        es_callback\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "1118px",
    "left": "93px",
    "top": "222px",
    "width": "394px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
