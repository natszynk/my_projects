{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Rozpoznawanie-twarzy\" data-toc-modified-id=\"Rozpoznawanie-twarzy-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Rozpoznawanie twarzy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dane---olivetti-faces\" data-toc-modified-id=\"Dane---olivetti-faces-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Dane - olivetti faces</a></span></li><li><span><a href=\"#przygotowanie-danych-treningowych-oraz-testowych\" data-toc-modified-id=\"przygotowanie-danych-treningowych-oraz-testowych-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>przygotowanie danych treningowych oraz testowych</a></span></li><li><span><a href=\"#Tworzymy-model-sieci-konwolucyjnej\" data-toc-modified-id=\"Tworzymy-model-sieci-konwolucyjnej-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Tworzymy model sieci konwolucyjnej</a></span></li><li><span><a href=\"#callbacks\" data-toc-modified-id=\"callbacks-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>callbacks</a></span></li><li><span><a href=\"#trening\" data-toc-modified-id=\"trening-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>trening</a></span></li><li><span><a href=\"#sprawdzamy-tensorboard\" data-toc-modified-id=\"sprawdzamy-tensorboard-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>sprawdzamy tensorboard</a></span></li></ul></li><li><span><a href=\"#Aktywacja-funkcją-&quot;sigmoid&quot;\" data-toc-modified-id=\"Aktywacja-funkcją-&quot;sigmoid&quot;-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Aktywacja funkcją \"sigmoid\"</a></span></li><li><span><a href=\"#Dodatkowe-źródła-informacji\" data-toc-modified-id=\"Dodatkowe-źródła-informacji-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Dodatkowe źródła informacji</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# jeśli nie korzystasz z poniższej paczki, to wykomentuj te dwie linie poniżej\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme=\"monokai\", context=\"notebook\", ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Powtórka\n",
    "- implementacja sieci konwolucyjnej w KERASIE\n",
    "- badanie i zapobieganie przeuczeniu\n",
    "- wzbogacenie modelu o _batch normalization_\n",
    "- wzbogacenie procesu uczenia o regularyzację\n",
    "- sprawdzenie różnicy w uczeniu podczas zastosowania aktywacji 'sigmoid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozpoznawanie twarzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane - olivetti faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "faces = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faces.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(faces.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### przygotowanie danych treningowych oraz testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = faces.images.reshape(-1,64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = faces.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzamy jakie są i ile jest klas\n",
    "print(\"Jakie klasy: \", np.unique(y_train))\n",
    "classNum = np.unique(y_train).shape[0]\n",
    "print(\"ile jest klas: \", classNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzymy model sieci konwolucyjnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSeqModel(activation=\"relu\", learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    funkcja do tworzenia modelu\n",
    "    :param activation: rodzaj funkcji aktywacji na wszystkich warstwach\n",
    "    :param learning_rate: współczynnik 'prędkości' uczenia\n",
    "    \"\"\"\n",
    "    # pusty model\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # pierwsza warstwa jako samo wejście\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(64,64,1)))\n",
    "    # pierwsza ukryta, konwolucyjna\n",
    "    model.add(tf.keras.layers.Conv2D(filters=16,\n",
    "                                     kernel_size=[3,3],\n",
    "                                     padding=\"same\",\n",
    "                                     activity_regularizer=tf.keras.regularizers.l1_l2(l1=0.001,\n",
    "                                                                                     l2=0.001)\n",
    "                                    ))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation(activation))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    # druga ukryta, konwolucyjna\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32,\n",
    "                                     kernel_size=[3,3],\n",
    "                                     padding=\"same\",\n",
    "                                     activity_regularizer=tf.keras.regularizers.l1_l2(l1=0.001,\n",
    "                                                                                     l2=0.001)\n",
    "                                    ))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation(activation))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    # spłaszczamy pod warstwy fully connected(Dense)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    # czwarta ukryta fully connetced\n",
    "    model.add(tf.keras.layers.Dense(64,\n",
    "                                    activity_regularizer=tf.keras.regularizers.l1_l2(l1=0.001,\n",
    "                                                                                     l2=0.001)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation(activation))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    # wyjściowa, zadaniem jest klasyfikacja\n",
    "    model.add(tf.keras.layers.Dense(classNum,\n",
    "                                    activity_regularizer=tf.keras.regularizers.l1_l2(l1=0.001,\n",
    "                                                                                     l2=0.001)))\n",
    "    # aktywacja jako softmax, aby uzyskać rozkład prawdopodbieństwa\n",
    "    model.add(tf.keras.layers.Softmax())\n",
    "    # żadnego dropout'u, nie chcemy abym nam wyzerowało wartość\n",
    "    \n",
    "    # drukujemy opis modelu\n",
    "    print(model.summary())\n",
    "    \n",
    "    # wybieramy optimalizator, polecam pobawić się z różnymi typami oraz różnymi wartościami learning rate'u\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    # kompilujemy\n",
    "    model.compile(optimizer=opt, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCallbacks(model, modelName):\n",
    "    \"\"\"\n",
    "    funkcja tworząca odpowiednie zestawienie callbacków\n",
    "    niektóre do podsumowania, a niektóre do kontroli treningu\n",
    "    :param model: model sieci w kerasie\n",
    "    :param modelName: nazwa modelu, w celu rozróżnienia w tensorboard\n",
    "    \"\"\"\n",
    "    # dodajemy zapisywanie logów do tensorboard'a\n",
    "    # katalog nazywa się jak model wraz z czasem utworzenia\n",
    "    log_dir = \"logs\\\\\" + modelName + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    ###############\n",
    "    # główny callback odnoszący się do samego modelu, wag i nmetryk\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    ###############\n",
    "    # callback kontrolujący spadek błędu na datasecie validacyjnym\n",
    "    # i zatrzymujący uczenie jeśli się nie poprawi przez ileśtam epok\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "    \n",
    "    ###############\n",
    "    # callback do gradientów\n",
    "    # utworzenie zapisywacza wartości\n",
    "    file_writer_grads = tf.summary.create_file_writer(log_dir+\"\\\\grads\")\n",
    "    # funkcja licząca gradienty\n",
    "    def calcGrads(epoch, logs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = model(x_train[:500])\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        \n",
    "        # Log gradients\n",
    "        with file_writer_grads.as_default():\n",
    "            #g_sum = tf.reduce_sum(grads[-1])\n",
    "            #tf.summary.histogram(\"grads\", grads[-1], step=epoch)\n",
    "            for g, w in zip(grads, model.trainable_weights):\n",
    "                tf.summary.histogram(w.name, g, step=epoch)\n",
    "    \n",
    "    # utworzenie callback'a od zapisywania gradientów\n",
    "    # na koniec każdej epoki\n",
    "    grads_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=calcGrads)\n",
    "    \n",
    "    ###############\n",
    "    # callback od tworzenia logów z f1_score\n",
    "    # utworzenie zapisywacza wartości\n",
    "    file_writer_f1 = tf.summary.create_file_writer(log_dir+\"\\\\f1\")\n",
    "\n",
    "    # funkcja licząca\n",
    "    def log_f1_score(epoch, logs):\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        f1Val = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_f1.as_default():\n",
    "            tf.summary.scalar(\"f1 score\", f1Val, step=epoch)\n",
    "\n",
    "    # utworzenie callback'a od zapisywania f1_score'a\n",
    "    # na koniec każdej epoki\n",
    "    f1_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_f1_score)\n",
    "    \n",
    "    # zwracamy listę callbacków\n",
    "    return [tensorboard_callback, es_callback, grads_callback, f1_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, batchSize, epochsNum, callbacks):\n",
    "    \"\"\"\n",
    "    funkcja wykonująca trening\n",
    "    :param model: model do wykonania treningu\n",
    "    :param batchSize: wielkość pojedynczej paczki danych podczas treningu\n",
    "    :param epochsNum: ilość epok treningu, czyli ile razy po całym datasecie przelecimy\n",
    "    :param callbacks: lista callbacków zapisywujących podsumowanie treningu\n",
    "    \"\"\"\n",
    "    history = model.fit(x_train, y_train, \n",
    "                        batch_size=batchSize, epochs=epochsNum, verbose=1, \n",
    "                        initial_epoch=0,\n",
    "                        validation_data=(x_test, y_test), \n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    # rysujemy wykres błędu\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.title(\"loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy model sieci, póki co lecimy na difolcie\n",
    "model = createSeqModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy podsumowania\n",
    "callbacks = createCallbacks(model, \"reluRegularizedLowCNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trenujemy model\n",
    "train(model, 20, 200, callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sprawdzamy tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uruchomienie serwera, jeżeli z poziomu notebooka nie działa, to należy uruchomić z cmd, ale bez '%'\n",
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aktywacja funkcją \"sigmoid\"\n",
    "- poprzednie wyniki porównujemy z siecią opartą o aktywację \"sigmoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy model sieci z \"sigmoid\"\n",
    "modelSigmoid = createSeqModel(\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy podsumowania\n",
    "callbacks = createCallbacks(model, \"sigmoidCNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trenujemy model\n",
    "train(modelSigmoid, 50, 200, callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatkowe źródła informacji\n",
    "- [Wyjaśnienie problemu zanikającego gradientu](https://towardsdatascience.com/the-problem-of-vanishing-gradients-68cea05e2625)\n",
    "- [Zastosowanie regularyzacji w praktyce](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/)\n",
    "- [Ciekawe zestawienie w działaniu warstwy BatchNorm oraz Regularization.](https://blog.janestreet.com/l2-regularization-and-batch-norm/)\n",
    "- [Dobre wyjaśnienie na czym polega oszukiwanie sieci](https://medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "1104px",
    "left": "825px",
    "top": "180px",
    "width": "288.396px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
