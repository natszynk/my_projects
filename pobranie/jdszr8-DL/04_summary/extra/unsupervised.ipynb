{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Prosta-sieć-kodująco-rozkodowująca-zdjęcia.\" data-toc-modified-id=\"Prosta-sieć-kodująco-rozkodowująca-zdjęcia.-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Prosta sieć kodująco-rozkodowująca zdjęcia.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dane---mnist\" data-toc-modified-id=\"Dane---mnist-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Dane - mnist</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Trening\" data-toc-modified-id=\"Trening-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Trening</a></span></li><li><span><a href=\"#Rysujemy-efekty-kodowania\" data-toc-modified-id=\"Rysujemy-efekty-kodowania-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Rysujemy efekty kodowania</a></span></li><li><span><a href=\"#Rysowanie-przestrzeni-kodowania\" data-toc-modified-id=\"Rysowanie-przestrzeni-kodowania-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Rysowanie przestrzeni kodowania</a></span></li></ul></li><li><span><a href=\"#Rozszerzenie-kodowania-o-warstwy-konwolucyjne\" data-toc-modified-id=\"Rozszerzenie-kodowania-o-warstwy-konwolucyjne-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Rozszerzenie kodowania o warstwy konwolucyjne</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Trening\" data-toc-modified-id=\"Trening-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Trening</a></span></li><li><span><a href=\"#Sprawdzenie-jakości\" data-toc-modified-id=\"Sprawdzenie-jakości-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Sprawdzenie jakości</a></span></li><li><span><a href=\"#rysowanie-przestrzeni-kodowania\" data-toc-modified-id=\"rysowanie-przestrzeni-kodowania-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>rysowanie przestrzeni kodowania</a></span></li></ul></li><li><span><a href=\"#Odszumianie-zdjęć\" data-toc-modified-id=\"Odszumianie-zdjęć-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Odszumianie zdjęć</a></span><ul class=\"toc-item\"><li><span><a href=\"#Zaszumianie-zdjęć---zadanie\" data-toc-modified-id=\"Zaszumianie-zdjęć---zadanie-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Zaszumianie zdjęć - zadanie</a></span></li><li><span><a href=\"#Model-odszumiający\" data-toc-modified-id=\"Model-odszumiający-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Model odszumiający</a></span></li><li><span><a href=\"#Trening\" data-toc-modified-id=\"Trening-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Trening</a></span></li><li><span><a href=\"#Sprawdzanie-jakości-odszumiania\" data-toc-modified-id=\"Sprawdzanie-jakości-odszumiania-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Sprawdzanie jakości odszumiania</a></span></li></ul></li><li><span><a href=\"#Tensorboard\" data-toc-modified-id=\"Tensorboard-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Tensorboard</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-klasyfikatora---zadanie-ewentualnie\" data-toc-modified-id=\"Model-klasyfikatora---zadanie-ewentualnie-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Model klasyfikatora - zadanie ewentualnie</a></span></li><li><span><a href=\"#Summary-i-Callback'i\" data-toc-modified-id=\"Summary-i-Callback'i-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Summary i Callback'i</a></span></li><li><span><a href=\"#Trening\" data-toc-modified-id=\"Trening-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Trening</a></span></li><li><span><a href=\"#Uruchomienie-tensorboard'a\" data-toc-modified-id=\"Uruchomienie-tensorboard'a-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Uruchomienie tensorboard'a</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Unsupervised Deep Learning__\n",
    "Podczas zajęć poznamy zastosowanie uczenia nienadzorowanego w deep learningu w celu zakodowania zdjęć a następnie wykorzystania tego samego mechanizmu do odszumiana zdjęć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import io\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# jeśli nie korzystasz z poniższej paczki, to wykomentuj te dwie linie poniżej\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme=\"monokai\", context=\"notebook\", ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prosta sieć kodująco-rozkodowująca zdjęcia.\n",
    "- skorzystamy z naszego ukochanego mnista ;)\n",
    "- stworzymy sieć składającą się z dwóch części\n",
    "    - enkodera, zejście z ilością cech w dół, aby jak najgęściej 'upakować' nasze dane\n",
    "    - dekodera, zwiększanie ilości cech w celu uzyskania zdjęcia wejściowego w jak najmniej zmienionej postaci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane - mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wczytujemy dane mnist'a z keras'a\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizujemy wartości pikseli z 0-255 do 0-1\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podgląd kilku - znamy już to dobrze ;)\n",
    "plt.matshow(x_train[0], cmap=cm.gray)\n",
    "plt.show()\n",
    "print(f\"label: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "- po wejściu do modelu spłaszczamy zdjęcia to rozmiaru wektora 784\n",
    "- enkoder będzie trzema warstwami fully connected z zmniejszającą się ilością neuronów\n",
    "- dekoder będzie trzema warstwami fully connected z rosnącą ilością neuronów, aż do 784\n",
    "- wychodząc zmieniamy kształ na zdjęcia 28,28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pusty kontener\n",
    "model = tf.keras.models.Sequential()\n",
    "# wejście i zmiana kształtu\n",
    "model.add(layers.InputLayer(input_shape=(28,28)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "############# enkoder #############\n",
    "# kompresja zdjęcia do 256 wartości\n",
    "model.add(layers.Dense(units=256, activation='relu'))\n",
    "# kompresja do 128 wartości\n",
    "model.add(layers.Dense(units=128, activation='relu'))\n",
    "# kompresja do 64 wartości, to jest nasze zakodowane zdjęcie\n",
    "model.add(layers.Dense(units=3, activation='relu', name='codedData'))\n",
    "\n",
    "############# dekoder #############\n",
    "# dekompresja do 128 wartości\n",
    "model.add(layers.Dense(units=128, activation='relu'))\n",
    "# dekompresja do 256 wartości\n",
    "model.add(layers.Dense(units=256, activation='relu'))\n",
    "# dekompresja do 784 wartości, wracamy do właściwej ilości\n",
    "model.add(layers.Dense(units=784, activation='relu'))\n",
    "\n",
    "# wyjściowow zmieniamy kształ na bardziej \"zdjęciowy\"\n",
    "model.add(layers.Reshape((28,28)))\n",
    "\n",
    "# wydruk podsumowania modelu\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy optymalizator\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kompilujemy model\n",
    "model.compile(optimizer=opt, loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykonujemy trening zapisując historię\n",
    "history = model.fit(x_train, x_train, batch_size=200, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rysujemy wykres błędu\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rysujemy efekty kodowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja do wyświetlania rekonstrukcji\n",
    "def showReconstruction(data, labels, name, model):\n",
    "    samplesNum = data.shape[0]\n",
    "    xOut = model.predict(data)\n",
    "    f,a=plt.subplots(2,samplesNum,figsize=(20,4))\n",
    "    for i in range(samplesNum):\n",
    "        a[0][i].matshow(data[i], cmap=cm.gray)\n",
    "        a[0][i].axis('off')\n",
    "        a[1][i].matshow(xOut[i], cmap=cm.gray)\n",
    "        a[1][i].axis('off')\n",
    "        a[1][i].set_title(labels[i])\n",
    "    plt.suptitle(name +\" data reconstruction\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rekonstrukcja przykładów ze zbioru treningowego\n",
    "recoNum = 10\n",
    "xIn = x_train[-recoNum:]\n",
    "yIn = y_train[-recoNum:]\n",
    "showReconstruction(xIn, yIn, \"Train\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rekonstrukcja przykładów ze zbioru testowego\n",
    "recoNum = 20\n",
    "xIn = x_test[-recoNum:]\n",
    "yIn = y_test[-recoNum:]\n",
    "showReconstruction(xIn, yIn, \"Test\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rysowanie przestrzeni kodowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy model częściowy, chcemy aby tylko zakodował zdjęcie\n",
    "intermediate_layer_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(\"codedData\").output)\n",
    "intermediate_output = intermediate_layer_model.predict(x_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy rysunek 3D z zakodowanych danych\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(intermediate_output[:,0], intermediate_output[:,1], intermediate_output[:,2], c=y_train[:1000])\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a teraz w 2D\n",
    "plt.scatter(intermediate_output[:,0], intermediate_output[:,2], c=y_train[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozszerzenie kodowania o warstwy konwolucyjne\n",
    "- dodamy do modelu warstwy konwolucyjne\n",
    "- przynajmniej jedna warstwa fully connected w środku\n",
    "- ilość warstw i neuronów dowolna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pusty kontener\n",
    "model = tf.keras.models.Sequential()\n",
    "# wejście ze zmianą wymiarowości\n",
    "model.add(layers.Reshape((28,28,1), input_shape=(28,28)))\n",
    "\n",
    "############# enkoder #############\n",
    "# ekstrakcja cech nr 1\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\"))\n",
    "# ekstrakcja cech nr 2\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "# spłaszczenie\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=784, activation='relu'))\n",
    "model.add(layers.Dense(units=392, activation='relu'))\n",
    "model.add(layers.Dense(units=196, activation='relu'))\n",
    "model.add(layers.Dense(units=98, activation='relu'))\n",
    "model.add(layers.Dense(units=49, activation='relu'))\n",
    "# kompresja do 3 wartości, to jest nasze zakodowane zdjęcie\n",
    "model.add(layers.Dense(units=3, activation='relu', name='codedData'))\n",
    "\n",
    "############# dekoder #############\n",
    "model.add(layers.Dense(units=49, activation='relu'))\n",
    "model.add(layers.Dense(units=98, activation='relu'))\n",
    "model.add(layers.Dense(units=196, activation='relu'))\n",
    "model.add(layers.Dense(units=392, activation='relu'))\n",
    "model.add(layers.Dense(units=784, activation='relu'))\n",
    "# dekompresja do 1568 wartości, jest to równowartość 7*7*32\n",
    "model.add(layers.Dense(units=1568, activation='relu'))\n",
    "# zmiana kształu pod konwolucje\n",
    "model.add(layers.Reshape((7, 7, 32)))\n",
    "# przejście przez konwolucje transponowane w celu zwiększenia rozmiaru zdjęcia\n",
    "#7x7x32\n",
    "model.add(layers.Conv2DTranspose(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\"))\n",
    "# przejście przez konwolucje transponowane w celu zwiększenia rozmiaru zdjęcia\n",
    "#14x14x16\n",
    "model.add(layers.Conv2DTranspose(filters=1, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\"))\n",
    "#28x28x1\n",
    "# wyjściowow zmieniamy kształ na bardziej \"zdjęciowy\"\n",
    "model.add(layers.Reshape((28,28)))\n",
    "\n",
    "# wydruk podsumowania modelu\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy optymalizator\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.003)\n",
    "#opt = tf.keras.optimizers.RMSprop(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kompilujemy model\n",
    "model.compile(optimizer=opt, loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykonujemy trening zapisując historię\n",
    "history = model.fit(x_train, x_train, batch_size=200, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rysujemy wykres błędu\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzenie jakości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rekonstrukcja przykładów ze zbioru treningowego\n",
    "recoNum = 10\n",
    "xIn = x_train[-recoNum:]\n",
    "yIn = y_train[-recoNum:]\n",
    "showReconstruction(xIn, yIn, \"Train\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rekonstrukcja przykładów ze zbioru testowego\n",
    "recoNum = 20\n",
    "xIn = x_test[-recoNum:]\n",
    "yIn = y_test[-recoNum:]\n",
    "showReconstruction(xIn, yIn, \"Test\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rysowanie przestrzeni kodowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy model częściowy, chcemy aby tylko zakodował zdjęcie\n",
    "intermediate_layer_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(\"codedData\").output)\n",
    "intermediate_output = intermediate_layer_model.predict(x_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy rysunek 3D z zakodowanych danych\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(intermediate_output[:,0], intermediate_output[:,1], intermediate_output[:,2], c=y_train[:1000])\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a teraz w 2D\n",
    "plt.scatter(intermediate_output[:,1], intermediate_output[:,2], c=y_train[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odszumianie zdjęć\n",
    "- sztucnie 'zniszczymy' zdjęcia mnista\n",
    "- sieć kodująco-rozkodująca się nie zmienia\n",
    "- nowe jesty porównanie w trakcie treningu zdjęć odszumionych przez sieć z oryginalnymi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zaszumianie zdjęć - zadanie\n",
    "- skorzystamy z numpy\n",
    "- szum będzie losowymi liczbami\n",
    "- dodajemy losowy szum do zdjęć/pikseli\n",
    "- rysujemy przykładowe wyniki zaszumiania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja zaszumiająca\n",
    "def makeSomeNoise(images, noiseStrengh = 0.1):\n",
    "    # pobieramy kształcałego zbioru do zaszumienia\n",
    "    imgsShape = images.shape\n",
    "    #print(\"imgs shape\", imgsShape)\n",
    "    # liczymy ile jest wszystkihc pikseli w zbiorze, do każdego osono coś dodamy\n",
    "    pixelsNum = imgsShape[0]*imgsShape[1]*imgsShape[2]\n",
    "    # generujemy szum i zmieniamy na kształ zbioru danych\n",
    "    noise = np.random.normal(0,noiseStrengh,pixelsNum).reshape(imgsShape[0],imgsShape[1],imgsShape[2])\n",
    "    # upewniamy się, że ilości się zgadzają\n",
    "    #print(\"noise shape\", noise.shape)\n",
    "    # ostatecznie dodajemy szum do zdjęć\n",
    "    imgsNoised = np.add(images, noise)\n",
    "    return imgsNoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja do wyświetlania serii zdjęć\n",
    "def showImages(data, name):\n",
    "    samplesNum = data.shape[0]\n",
    "    f,a=plt.subplots(1,samplesNum,figsize=(20,4))\n",
    "    for i in range(samplesNum):\n",
    "        a[i].matshow(data[i], cmap=cm.gray)\n",
    "        a[i].axis('off')\n",
    "    plt.suptitle(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImages(x_train[:10], \"Original MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImages(makeSomeNoise(x_train[:10], 0.3), \"Noised MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zaszumiamy cały dataset\n",
    "x_train_noised = makeSomeNoise(x_train, 0.3)\n",
    "x_test_noised = makeSomeNoise(x_test, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model odszumiający\n",
    "- architektura modelu będzie podobna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pusty kontener\n",
    "model = tf.keras.models.Sequential()\n",
    "# wejście ze zmianą wymiarowości\n",
    "model.add(layers.Reshape((28,28,1), input_shape=(28,28)))\n",
    "\n",
    "############# enkoder #############\n",
    "# ekstrakcja cech nr 1\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\"))\n",
    "# ekstrakcja cech nr 2\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "# spłaszczenie\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=784, activation='relu'))\n",
    "# kompresja do 3 wartości, to jest nasze zakodowane zdjęcie\n",
    "model.add(layers.Dense(units=392, activation='relu'))\n",
    "\n",
    "############# dekoder #############\n",
    "model.add(layers.Dense(units=784, activation='relu'))\n",
    "# dekompresja do 1568 wartości, jest to równowartość 7*7*32\n",
    "model.add(layers.Dense(units=1568, activation='relu'))\n",
    "# zmiana kształu pod konwolucje\n",
    "model.add(layers.Reshape((7, 7, 32)))\n",
    "# przejście przez konwolucje transponowane w celu zwiększenia rozmiaru zdjęcia\n",
    "model.add(layers.Conv2DTranspose(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\"))\n",
    "# przejście przez konwolucje transponowane w celu zwiększenia rozmiaru zdjęcia\n",
    "model.add(layers.Conv2DTranspose(filters=1, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "# wyjściowow zmieniamy kształ na bardziej \"zdjęciowy\"\n",
    "model.add(layers.Reshape((28,28)))\n",
    "\n",
    "# wydruk podsumowania modelu\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy optymalizator\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "#opt = tf.keras.optimizers.RMSprop(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kompilujemy model\n",
    "model.compile(optimizer=opt, loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening\n",
    "- tym razem jako dane wejściowe podajemy zaszumione\n",
    "- zaś jako wyjściowe podajemy oryginalne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykonujemy trening zapisując historię\n",
    "history = model.fit(x_train_noised, x_train, batch_size=200, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rysujemy wykres błędu\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzanie jakości odszumiania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howMany = 20\n",
    "# oryginalne\n",
    "showImages(x_train[:howMany], \"Original MNIST\")\n",
    "# zaszumione\n",
    "showImages(x_train_noised[:howMany], \"Noised MNIST\")\n",
    "# oszumione\n",
    "showImages(model.predict(x_train_noised[:howMany]), \"Unnoised MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howMany = 20\n",
    "# oryginalne\n",
    "showImages(x_test[:howMany], \"Original MNIST\")\n",
    "# zaszumione\n",
    "showImages(x_test_noised[:howMany], \"Noised MNIST\")\n",
    "# oszumione\n",
    "showImages(model.predict(x_test_noised[:howMany]), \"Unnoised MNIST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "- poznamy narzędzie zintegrowane z tensorflow do wizualizacji\n",
    "    - postępu uczenia w postaci wykresów błędu i jakości modelu\n",
    "    - architektury modelu\n",
    "    - wartości poszczególnych wag modelu\n",
    "    - podglądu przykłądowych wejść oraz wyjść"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model klasyfikatora - zadanie ewentualnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kontener na model\n",
    "model = tf.keras.models.Sequential()\n",
    "# pierwsza warstwa zmienia kształ na odpowiadający pod konwolucje, czyli 4D, posiada również rozmiar wejścia\n",
    "model.add(tf.keras.layers.Reshape(target_shape=(28,28,1), input_shape=(28,28)))\n",
    "# pierwsza ukryta, konwolucyjna\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=[3,3], padding=\"same\"))\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "# druga ukryta, konwolucyjna\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=[3,3], padding=\"same\"))\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "# trzecia ukryta, konwolucyjna\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=[3,3], padding=\"same\"))\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "# spłaszczamy pod warstwy fully connected(Dense)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# czwarta ukryta fully connetced\n",
    "model.add(tf.keras.layers.Dense(128))\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "# wyjściowa, zadaniem jest klasyfikacja 10 klas\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "# aktywacja jako softmax, aby uzyskać rozkład prawdopodbieństwa\n",
    "model.add(tf.keras.layers.Softmax())\n",
    "# żadnego dropout'u, nie chcemy abym nam wyzerowało wartość"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drukujemy opis modelu\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wybieramy optimalizator, polecam pobawić się z różnymi typami oraz różnymi wartościami learning rate'u\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# kompilujemy\n",
    "model.compile(optimizer=opt, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary i Callback'i\n",
    "- tworzymy zapisywanie do plików naszych wyników\n",
    "- skorzystamy z wbudowanej funkcji w kerasa a także z ręcznie robionych callback'ów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nazwy klas\n",
    "class_names = \"0 1 2 3 4 5 6 7 8 9\".split()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodajemy zapisywanie logów do tensorboard'a\n",
    "log_dir = \"logs\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, )\n",
    "# tworzymy obiekt zapisujący confusion matrix podczas treningu\n",
    "imgs_dir = log_dir + \"\\\\imgs\"\n",
    "file_writer_cm = tf.summary.create_file_writer(imgs_dir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "  # Save the plot to a PNG in memory.\n",
    "  buf = io.BytesIO()\n",
    "  plt.savefig(buf, format='png')\n",
    "  # Closing the figure prevents it from being displayed directly inside\n",
    "  # the notebook.\n",
    "  plt.close(figure)\n",
    "  buf.seek(0)\n",
    "  # Convert PNG buffer to TF image\n",
    "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "  # Add the batch dimension\n",
    "  image = tf.expand_dims(image, 0)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "  \"\"\"\n",
    "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "  Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "  \"\"\"\n",
    "  figure = plt.figure(figsize=(8, 8))\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "  plt.title(\"Confusion matrix\")\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(class_names))\n",
    "  plt.xticks(tick_marks, class_names, rotation=45)\n",
    "  plt.yticks(tick_marks, class_names)\n",
    "\n",
    "  # Normalize the confusion matrix.\n",
    "  cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "  # Use white text if squares are dark; otherwise black.\n",
    "  threshold = cm.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "  # Use the model to predict the values from the validation dataset.\n",
    "  y_pred = model.predict(x_test)\n",
    "  y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "  # Calculate the confusion matrix.\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  # Log the confusion matrix as an image summary.\n",
    "  figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "  cm_image = plot_to_image(figure)\n",
    "\n",
    "  # Log the confusion matrix as an image summary.\n",
    "  with file_writer_cm.as_default():\n",
    "    tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "\n",
    "# Define the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening\n",
    "- trenujemy i badamy różne ilości epok oraz rozmiary batchy\n",
    "- test przy pomocy metody wbudowanej evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trenujemy, warto sprawdzić z różną wielkością batcha i epok\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=1000, epochs=5, verbose=1, \n",
    "                    initial_epoch=0,\n",
    "                    validation_data=(x_test, y_test), \n",
    "                    callbacks=[tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rysujemy wykres błędu\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uruchomienie tensorboard'a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uruchomienie serwera, jeżeli z poziomu notebooka nie działa, to należy uruchomić z cmd, ale bez '%'\n",
    "#%tensorboard --logdir \"logs\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "1069.33px",
    "left": "809px",
    "top": "180px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
