{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Zadanie.-Rekurencyjna-rozgrzewka.\" data-toc-modified-id=\"Zadanie.-Rekurencyjna-rozgrzewka.-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Zadanie. Rekurencyjna rozgrzewka.</a></span></li><li><span><a href=\"#Warstwy-rekurencyjne\" data-toc-modified-id=\"Warstwy-rekurencyjne-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Warstwy rekurencyjne</a></span></li><li><span><a href=\"#Modelowanie-sinusa\" data-toc-modified-id=\"Modelowanie-sinusa-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modelowanie sinusa</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dane\" data-toc-modified-id=\"Dane-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Dane</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Trening\" data-toc-modified-id=\"Trening-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Trening</a></span></li><li><span><a href=\"#Predykcja-kolejnego-elementu\" data-toc-modified-id=\"Predykcja-kolejnego-elementu-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Predykcja kolejnego elementu</a></span></li><li><span><a href=\"#Zadanie.-Jak-daleko-w-przyszłość-dobrze-sobie-poradzi-?\" data-toc-modified-id=\"Zadanie.-Jak-daleko-w-przyszłość-dobrze-sobie-poradzi-?-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Zadanie. Jak daleko w przyszłość dobrze sobie poradzi ?</a></span></li></ul></li><li><span><a href=\"#Predykcja-szeregów-czasowych\" data-toc-modified-id=\"Predykcja-szeregów-czasowych-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Predykcja szeregów czasowych</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dane\" data-toc-modified-id=\"Dane-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Dane</a></span></li><li><span><a href=\"#dzielimy-dane-na-trening-i-test\" data-toc-modified-id=\"dzielimy-dane-na-trening-i-test-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>dzielimy dane na trening i test</a></span></li><li><span><a href=\"#Budujemy-model\" data-toc-modified-id=\"Budujemy-model-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Budujemy model</a></span></li><li><span><a href=\"#Dodajemy-logowanie-wyników-do-tensorboard.\" data-toc-modified-id=\"Dodajemy-logowanie-wyników-do-tensorboard.-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Dodajemy logowanie wyników do tensorboard.</a></span></li><li><span><a href=\"#Trening\" data-toc-modified-id=\"Trening-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Trening</a></span></li><li><span><a href=\"#Zadanie---Prezentacja-w-działaniu-i-porównanie-wyniku-różnych-architektur\" data-toc-modified-id=\"Zadanie---Prezentacja-w-działaniu-i-porównanie-wyniku-różnych-architektur-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Zadanie - Prezentacja w działaniu i porównanie wyniku różnych architektur</a></span></li><li><span><a href=\"#Jak-daleko-w-przyszłość-dobrze-sobie-poradzi-?\" data-toc-modified-id=\"Jak-daleko-w-przyszłość-dobrze-sobie-poradzi-?-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Jak daleko w przyszłość dobrze sobie poradzi ?</a></span></li></ul></li><li><span><a href=\"#Tekst:-Ocenianie-wiadomości,-spam-or-not\" data-toc-modified-id=\"Tekst:-Ocenianie-wiadomości,-spam-or-not-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Tekst: Ocenianie wiadomości, spam or not</a></span><ul class=\"toc-item\"><li><span><a href=\"#Wczytanie-i-obróbka-danych\" data-toc-modified-id=\"Wczytanie-i-obróbka-danych-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Wczytanie i obróbka danych</a></span></li><li><span><a href=\"#tokenizacja-danych\" data-toc-modified-id=\"tokenizacja-danych-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>tokenizacja danych</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Trening-i-test\" data-toc-modified-id=\"Trening-i-test-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Trening i test</a></span></li><li><span><a href=\"#tworzymy-wykres-ROC---Receiver-Operating-Characteristic\" data-toc-modified-id=\"tworzymy-wykres-ROC---Receiver-Operating-Characteristic-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>tworzymy wykres ROC - Receiver Operating Characteristic</a></span></li><li><span><a href=\"#Zadanie:-Callback-f1-score\" data-toc-modified-id=\"Zadanie:-Callback-f1-score-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Zadanie: Callback f1-score</a></span></li></ul></li><li><span><a href=\"#Klasyfikacja-Newsów\" data-toc-modified-id=\"Klasyfikacja-Newsów-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Klasyfikacja Newsów</a></span><ul class=\"toc-item\"><li><span><a href=\"#wczytywanie-danych\" data-toc-modified-id=\"wczytywanie-danych-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>wczytywanie danych</a></span></li><li><span><a href=\"#analiza-danych\" data-toc-modified-id=\"analiza-danych-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>analiza danych</a></span></li><li><span><a href=\"#one-hot-encodding-wyjść\" data-toc-modified-id=\"one-hot-encodding-wyjść-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>one hot encodding wyjść</a></span></li><li><span><a href=\"#podział-na-trening-i-test\" data-toc-modified-id=\"podział-na-trening-i-test-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>podział na trening i test</a></span></li><li><span><a href=\"#tokenizacja-tekstu\" data-toc-modified-id=\"tokenizacja-tekstu-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>tokenizacja tekstu</a></span></li><li><span><a href=\"#Zadanie\" data-toc-modified-id=\"Zadanie-6.6\"><span class=\"toc-item-num\">6.6&nbsp;&nbsp;</span>Zadanie</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-6.6.1\"><span class=\"toc-item-num\">6.6.1&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#trening\" data-toc-modified-id=\"trening-6.6.2\"><span class=\"toc-item-num\">6.6.2&nbsp;&nbsp;</span>trening</a></span></li><li><span><a href=\"#test\" data-toc-modified-id=\"test-6.6.3\"><span class=\"toc-item-num\">6.6.3&nbsp;&nbsp;</span>test</a></span></li></ul></li></ul></li><li><span><a href=\"#Hybryda-cnn+rnn:-Rozpoznawanie-ciągu-cyfr\" data-toc-modified-id=\"Hybryda-cnn+rnn:-Rozpoznawanie-ciągu-cyfr-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Hybryda cnn+rnn: Rozpoznawanie ciągu cyfr</a></span><ul class=\"toc-item\"><li><span><a href=\"#Wczytujemy-i-podglądamy-dataset\" data-toc-modified-id=\"Wczytujemy-i-podglądamy-dataset-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Wczytujemy i podglądamy dataset</a></span></li><li><span><a href=\"#tworzymy-generator-ciągów-cyfr\" data-toc-modified-id=\"tworzymy-generator-ciągów-cyfr-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>tworzymy generator ciągów cyfr</a></span></li><li><span><a href=\"#Tworzymy-model\" data-toc-modified-id=\"Tworzymy-model-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Tworzymy model</a></span></li><li><span><a href=\"#Testowanie\" data-toc-modified-id=\"Testowanie-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Testowanie</a></span></li><li><span><a href=\"#Zadanie:-Sprawdzenie-przy-jakiej-długości-ciągów-cyfr-skuteczność-klasyfikatora-drastycznie-spadnie.\" data-toc-modified-id=\"Zadanie:-Sprawdzenie-przy-jakiej-długości-ciągów-cyfr-skuteczność-klasyfikatora-drastycznie-spadnie.-7.5\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>Zadanie: Sprawdzenie przy jakiej długości ciągów cyfr skuteczność klasyfikatora drastycznie spadnie.</a></span></li></ul></li><li><span><a href=\"#Dodatkowe-materiały\" data-toc-modified-id=\"Dodatkowe-materiały-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Dodatkowe materiały</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, auc, roc_curve, f1_score, r2_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# jeśli nie korzystasz z poniższej paczki, to wykomentuj te dwie linie poniżej\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme=\"monokai\", context=\"notebook\", ticks=True, grid=False)\n",
    "\n",
    "# w razie wywalającego się tensorflow'a\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Rekurencyjne sieci neuronowe__\n",
    "- rodzaj sieci uwzględniający zmnienność danych w czasie\n",
    "- korzysta ze sprzężenia zwrotnego\n",
    "- składa się z bramek posiadających 'pamięć', np. GRU, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie. Rekurencyjna rozgrzewka.\n",
    "- Napisać funkcję obliczającą silnię\n",
    "- przykład: _4! = 1x2x3x4 = 24_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warstwy rekurencyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqLen = 7\n",
    "featNum = 2\n",
    "x = np.arange(int(seqLen*featNum)).astype(np.float32)\n",
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reshape(1,seqLen,featNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpLSTM = layers.LSTM(\n",
    "    units=3,\n",
    "    input_shape=(seqLen, featNum),\n",
    "    return_sequences=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpLSTM(x.reshape(1,seqLen,featNum)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelowanie sinusa\n",
    "- wygenerujemy dane sinusoidalne\n",
    "- zamodelujemy sieć, która będzie kontynuaować owe dane\n",
    "- porównamy sieć fully connected z rekurencyjną"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prec = 0.2\n",
    "y_clean = np.sin(np.arange(0,20,x_prec)).astype(np.float32)\n",
    "x = y_clean+(np.random.rand(y_clean.shape[0]) - 0.5)*0.5\n",
    "plt.plot(x)\n",
    "plt.plot(y_clean)\n",
    "plt.legend([\"zaszumiony\", \"czysty\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dane\n",
    "[1,2,3,4,5,6]\n",
    "\n",
    "X          Y\n",
    "[1,2,3] -> [4]\n",
    "[2,3,4] -> [5]\n",
    "[3,4,5] -> [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamiana danych na sekwencję, wymagają tego warstwy rekurencyjne\n",
    "# długość sekwencji zależy od tego po jakiej ilości próbek w czasie chcemy aby rekurencja chodziła\n",
    "def ConvertDataToSequence(data, windowLen, featNum):\n",
    "    \"\"\"\n",
    "    :param data: dane w postaci szeregu, typu numpy.array\n",
    "    :param windowLen: długość okna czyli sekwencji\n",
    "    :param featNum: ilość cech w ramach szeregu\n",
    "    \"\"\"\n",
    "    #długość wejściowego szeregu\n",
    "    lenOfAllSeq = data.shape[0]\n",
    "    # pusty kontener na kolejne sekwencje\n",
    "    xSeq = []\n",
    "    # idziemy po szeregu i tworzymy z niego sekwencje\n",
    "    for i in range(lenOfAllSeq-windowLen):\n",
    "        xSeq.append(data[i:i+windowLen])\n",
    "    xSeq = np.array(xSeq).reshape(-1,windowLen,featNum)\n",
    "    \n",
    "    # definiujemy wartości następujące po każdej sekwencji, będą to nasze wyjścia\n",
    "    y = data[windowLen:,0].reshape(-1,1)\n",
    "    \n",
    "    return xSeq, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy sekwencje z naszego szeregu oraz odpowiadające po seknwecjach odpowiedzi\n",
    "seqLen = 20\n",
    "featNum = 1\n",
    "xSeq, y = ConvertDataToSequence(x.reshape(-1,1), seqLen, featNum)\n",
    "print(f\"xSeq:\\n{xSeq[:5]}\")\n",
    "print(f\"y:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyświetlamy dane sekwencyjne\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(xSeq.reshape(-1,seqLen))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "- wejście jest pojedynczą sekwencją\n",
    "- architekturą będzie prosta jednowarstwowa sieć LSTM\n",
    "- porównamy z siecią ANN\n",
    "- później dodamy kolejną warstwę LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRNN = tf.keras.Sequential()\n",
    "modelRNN.add(\n",
    "    layers.InputLayer(\n",
    "        input_shape=(seqLen,featNum)\n",
    "    )\n",
    ")\n",
    "\"\"\"\n",
    "modelRNN.add(\n",
    "    layers.Flatten()\n",
    ")\n",
    "\n",
    "modelRNN.add(\n",
    "    layers.Dense(\n",
    "        units=128,\n",
    "        activation=\"relu\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "modelRNN.add(\n",
    "    layers.LSTM(\n",
    "        units=128,\n",
    "        return_sequences=True\n",
    "    )\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "modelRNN.add(\n",
    "    layers.LSTM(\n",
    "        units=128\n",
    "    )\n",
    ")\n",
    "\n",
    "modelRNN.add(\n",
    "    layers.Dense(\n",
    "        units=1\n",
    "    )\n",
    ")\n",
    "\n",
    "modelRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRNN.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=\"mse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = modelRNN.fit(\n",
    "    x = xSeq,\n",
    "    y = y,\n",
    "    batch_size=1,\n",
    "    epochs=20,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predykcja kolejnego elementu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xSeq[-1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRNN.predict(xSeq[-1::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelRNN.predict(xSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(y)\n",
    "plt.plot(y_pred.reshape(-1))\n",
    "plt.plot(y_clean[seqLen:])\n",
    "plt.legend([\"referencja\", \"predykcja\", \"czysta referencja\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r^2 dla jednej warstwy LSTM oraz dense\n",
    "r2_score(y_clean[seqLen:], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie. Jak daleko w przyszłość dobrze sobie poradzi ?\n",
    "- sprawdzimy ile próbek w przód dane z sieci będą sensowne\n",
    "- zaczniemy od ostatniej sekwencji w zbiorze\n",
    "- potem sieć będzie zasilania próbkami, które sama wygeneruje\n",
    "- ostatecznie wyświetlimy serię wszystkich predykcji"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dane\n",
    "[1,2,3,4,5,6]\n",
    "\n",
    "trening\n",
    "X          Y\n",
    "[1,2,3] -> [4]\n",
    "[2,3,4] -> [5]\n",
    "[3,4,5] -> [6]\n",
    "...\n",
    "testowanie\n",
    "[4,5,6] -> [7.02]\n",
    "[5,6,7.02] -> [8.1]\n",
    "[6,7.02,8.1] -> [9.03]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predykcja szeregów czasowych\n",
    "- przewidywanie wartości temperatury\n",
    "- porównamy różne wersje sieci rekurencyjnych z siecią gęstą(fully connected)\n",
    "- wyniki prezentujemy w tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane\n",
    "- wczytujemy dane z arkusza ```data/daily-minimum-temperatures-in-me.csv```\n",
    "- tworzymy sekwencje i odpowiedzi\n",
    "- dzielimy sekwencje na treningowe oraz testowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_parser = lambda x: datetime.strptime(x, '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/daily-minimum-temperatures-in-me.csv\",\n",
    "    parse_dates=['Date'],\n",
    "    date_parser=date_parser\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = pd.DatetimeIndex(df['Date']).month\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = pd.to_numeric(df[\"Daily minimum temperatures\"], errors='coerce').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = pd.to_numeric(df[\"month\"], errors='coerce').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x1.reshape(-1,1), x2.reshape(-1,1)), axis=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featNum = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~np.isreal(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(~np.isreal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_idx = np.where(np.isnan(x))\n",
    "nan_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.isinf(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nany uzupełniamy średnią z sąsiadujących wartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tmp = (x[564,0] + x[567,0])/2\n",
    "x_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[565,0] = x_tmp\n",
    "x[566,0] = x_tmp\n",
    "np.where(np.isnan(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tmp = (x[1289,0] + x[1291,0])/2\n",
    "x[1290,0] = x_tmp\n",
    "np.where(np.isnan(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(x[:,0], 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.hist(x[:,0],bins=27)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = MinMaxScaler().fit_transform(x.reshape(-1,featNum))\n",
    "x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqLen = 7\n",
    "featNum = 2\n",
    "xSeq, y = ConvertDataToSequence(x, seqLen, featNum)\n",
    "print(f\"sequence shape: {xSeq.shape}\")\n",
    "print(f\"output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(xSeq[:50,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dzielimy dane na trening i test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = xSeq.shape[0]\n",
    "x_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num = int(x_len*(1.0-test_percent))\n",
    "x_train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_num = int(x_len*test_percent)\n",
    "x_test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num+x_test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_num = x_len - x_train_num\n",
    "x_test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xSeq_train = xSeq[:x_train_num]\n",
    "xSeq_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xSeq_test = xSeq[-x_test_num:] #[x_train_num:]\n",
    "xSeq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[:x_train_num]\n",
    "y_test = y[-x_test_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(np.arange(x_train_num), xSeq_train[:,0,0])\n",
    "plt.plot(np.arange(x_train_num, x_len), xSeq_test[:,0,0])\n",
    "plt.legend([\"train\",\"test\"])\n",
    "plt.title(\"data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budujemy model\n",
    "- wstępnie prosta sieć rekurencyjna\n",
    "- potem wielowarstwowa sieć rekurencyjna\n",
    "- na koniec sieć rekurencyjna dwukierunkowa(bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRNN = tf.keras.Sequential()\n",
    "\n",
    "modelRNN.add(\n",
    "    layers.LSTM(\n",
    "        units=256,\n",
    "        input_shape=(seqLen, featNum),\n",
    "        name=\"rekurencja_pierwsza\",\n",
    "        return_sequences=True\n",
    "    )\n",
    ")\n",
    "\n",
    "modelRNN.add(\n",
    "    layers.Dropout(0.3)\n",
    ")\n",
    "\n",
    "modelRNN.add(\n",
    "    layers.LSTM(\n",
    "        units=256,\n",
    "        name=\"rekurencja_druga\"\n",
    "    )\n",
    ")\n",
    "\n",
    "modelRNN.add(\n",
    "    layers.Dense(\n",
    "        units=256,\n",
    "        activation=\"relu\"\n",
    "    )\n",
    ")\n",
    "\n",
    "modelRNN.add(\n",
    "    layers.Dropout(0.5)\n",
    ")\n",
    "\n",
    "modelRNN.add(\n",
    "    layers.Dense(\n",
    "        units=1,\n",
    "        name=\"wyjscie\"\n",
    "    )\n",
    ")\n",
    "\n",
    "modelRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRNN.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=\"mse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodajemy logowanie wyników do tensorboard.\n",
    "- chcemy wyświetlić na koniec treningu(czyli tylko raz) jak model pracuje na danych testowych\n",
    "- ponadto chcemy jednocześnie mieć to nałożone na referencyjne wartości\n",
    "- należy skorzystać z metody ```tf.summary.scalar(???)```\n",
    "- jednak zapisać należy cały przebieg na danych testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs\\\\\" + \"lstm_256_dropout_256_dense_256_dropout_two_features_2\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir,\n",
    "    histogram_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer_preds = tf.summary.create_file_writer(logdir+\"\\\\preds\")\n",
    "file_writer_ref = tf.summary.create_file_writer(logdir+\"\\\\ref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_predictions_refs(logs):\n",
    "    y_pred = modelRNN.predict(xSeq_test)\n",
    "    \n",
    "    for i in range(y_pred.shape[0]):\n",
    "        with file_writer_preds.as_default():\n",
    "            tf.summary.scalar(\"output\", y_pred[i,0], step=i)\n",
    "        with file_writer_ref.as_default():\n",
    "            tf.summary.scalar(\"output\", y_test[i,0], step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_train_end=log_predictions_refs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback zapisujący reszty, czyli różnice predykcji od referencji\n",
    "file_writer_err = tf.summary.create_file_writer(logdir+\"\\\\err\")\n",
    "\n",
    "def log_err(epoch, logs):\n",
    "    y_pred = modelRNN.predict(xSeq_test)\n",
    "    y_err = y_test - y_pred\n",
    "    with file_writer_err.as_default():\n",
    "        tf.summary.histogram(\"errors\", y_err, step=epoch)\n",
    "\n",
    "err_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=log_err\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = modelRNN.fit(\n",
    "    x=xSeq_train,\n",
    "    y=y_train,\n",
    "    epochs=20,\n",
    "    batch_size=7,\n",
    "    validation_data=(xSeq_test, y_test),\n",
    "    callbacks=[tensorboard_callback, test_callback, err_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykres reszt\n",
    "y_pred = modelRNN.predict(xSeq_test)\n",
    "y_err = y_test - y_pred\n",
    "plt.plot(y_err)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_err, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie - Prezentacja w działaniu i porównanie wyniku różnych architektur\n",
    "- wykonać należy porównanie predykcji modelu z referencją na zbiorze testowym\n",
    "- w miarę możliwość wykonać kilka eksperymentów z różnymi architekturami\n",
    "- zestawić wyniki w tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak daleko w przyszłość dobrze sobie poradzi ?\n",
    "- sprawdzimy ile próbek w przód dane z sieci będą sensowne\n",
    "- zaczniemy od początku testowego, potem sieć będzie zasilania próbkami, które sama wygeneruje\n",
    "- ostatecznie policzymy jak daleko się znalazły winiki od referencyjnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jak daleko sprawdzamy\n",
    "howFar = y_test.shape[0]\n",
    "# kontener na zbiorcze predykcje\n",
    "y_predAll = []\n",
    "# pierwsza sekwencja testowa, znana nam\n",
    "xSeqIn = xSeq_test[0]\n",
    "# lecimy jak daleko chcemy\n",
    "for i in range(howFar-seqLen):\n",
    "    # wyznaczamy predykcję\n",
    "    y_pred = modelRNN.predict(xSeqIn.reshape(1,seqLen,featNum))\n",
    "    # podmieniamy\n",
    "    x1_seq_new = updateSeq(xSeqIn[:,0], y_pred[0][0])\n",
    "    x2_seq_new = xSeq_test[i+1,:,1]\n",
    "    xSeqIn = np.concatenate(\n",
    "        (\n",
    "            x1_seq_new.reshape(-1,1),\n",
    "            x2_seq_new.reshape(-1,1)\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    # wstawiamy do wektora zbiorczego predykcji\n",
    "    y_predAll.append(y_pred[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykreślenie predykcji na tle referencji\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(y_test)\n",
    "plt.plot(y_predAll)\n",
    "plt.legend([\"powinno być\", \"jest teraz\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tekst: Ocenianie wiadomości, spam or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie i obróbka danych\n",
    "- przy pomocy pandasa wczytujemy arkusz ```spam.csv```\n",
    "- czyścimy niepotrzebne rzeczy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/spam.csv',delimiter=',',encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwamy zbędne kolumny\n",
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = df.v1.unique()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df.v1.value_counts().values\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.v1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykreślamy ilościowy udział klas\n",
    "plt.bar(\n",
    "    x=class_names,\n",
    "    height=class_counts\n",
    ")\n",
    "plt.xlabel('Label')\n",
    "plt.title('Number of ham and spam messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyznaczamy dane wejściowe\n",
    "x = df.v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyznaczamy dane wyjściowe wraz z tranformacją na klasy\n",
    "y = LabelEncoder().fit_transform(df.v1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dzielimy na trening i test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizacja danych\n",
    "- zamiana słów na odpowiadające im indeksy\n",
    "- podział zdań na osobne słowa\n",
    "- tworzone są wektory słów\n",
    "- dodawane są paddingi, aby każdy wektor był takiej samej długości\n",
    "- będą to nasze sekwencje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyciągamy wszystkie słowa\n",
    "all_words = df.v2.str.split(\" \").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamieniamy na stringi i liczymy ile jest unikatowych\n",
    "unique_words, unique_words_cnts = np.unique(np.array(all_words), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyświetlamy ilości\n",
    "print(f\"Liczba unikalnych słów: {unique_words.shape[0]}\")\n",
    "print(f\"Ile jest słów, które co najmniej 10 razy wystąpiły: {unique_words_cnts[unique_words_cnts>10].shape[0]}\")\n",
    "print(f\"Jakie słowa są najczęściej występujące: {unique_words[np.where(unique_words_cnts>500)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(unique_words_cnts, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maksymalna ilość słów w słownika\n",
    "max_words = 1000\n",
    "# maksymalna długość wektora słów (zdania)\n",
    "max_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obiekt Tokenizatora, czyli konwertera słów na indeksy\n",
    "tok = Tokenizer(num_words=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trenujemy tokenizator na danych treningowych\n",
    "tok.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konwersja textu na wektory\n",
    "sequences = tok.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utworzenie macierzy sekwencji z paddingami\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podejrzenie jak wyglądają dane jednej próbki\n",
    "sequences_matrix[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dane testowe\n",
    "test_sequences = tok.texts_to_sequences(x_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences_matrix[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.sequences_to_texts([test_sequences_matrix[11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "- tworzymy model sieci rekurencyjnej opartej o komórki LSTM\n",
    "- wejściowe wektory dodatkowo przenosimy w większą ilość wymiarów za pomocą warstwy embedding\n",
    "- dodajemy warstwę fully connected we celu przetworzenia wyłuskanych informacji\n",
    "- wyjściowo chcemy mieć jedną wartość, ponieważ mamy do czynienia z klasyfikacją"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sentence\n",
    "['and are phone services call']\n",
    "\n",
    "tokenized sentence\n",
    "[7,  21, 117, 709,  16]\n",
    "\n",
    "embedding, 5\n",
    "[\n",
    "[?, ?, ?, ?, ?],\n",
    "[?, ?, ?, ?, ?],\n",
    "[?, ?, ?, ?, ?],\n",
    "[?, ?, ?, ?, ?],\n",
    "[?, ?, ?, ?, ?]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pusty model\n",
    "modelSpam = tf.keras.models.Sequential()\n",
    "\n",
    "modelSpam.add(\n",
    "    layers.InputLayer(\n",
    "        name=\"wejscie\",\n",
    "        input_shape=(max_len)\n",
    "    )\n",
    ")\n",
    "\n",
    "modelSpam.add(\n",
    "    layers.Embedding(\n",
    "        input_dim = max_words,\n",
    "        output_dim=128\n",
    "    )\n",
    ")\n",
    "\n",
    "modelSpam.add(\n",
    "    layers.LSTM(\n",
    "        units=128,\n",
    "        return_sequences=True\n",
    "    )\n",
    ")\n",
    "\n",
    "modelSpam.add(\n",
    "    layers.LSTM(\n",
    "        units=128\n",
    "    )\n",
    ")\n",
    "\n",
    "modelSpam.add(\n",
    "    layers.Dense(\n",
    "        units=1,\n",
    "        activation=\"sigmoid\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# wydruk architektury\n",
    "modelSpam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optymalizator\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kompilacja z podaniem funkcji błędu i metryki\n",
    "modelSpam.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening i test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCallbacks(model, modelName):\n",
    "    \"\"\"\n",
    "    funkcja tworząca odpowiednie zestawienie callbacków\n",
    "    niektóre do podsumowania, a niektóre do kontroli treningu\n",
    "    :param model: model sieci w kerasie\n",
    "    :param modelName: nazwa modelu, w celu rozróżnienia w tensorboard\n",
    "    \"\"\"\n",
    "    # dodajemy zapisywanie logów do tensorboard'a\n",
    "    # katalog nazywa się jak model wraz z czasem utworzenia\n",
    "    log_dir = \"logs\\\\\" + modelName + \"_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    ###############\n",
    "    # główny callback odnoszący się do samego modelu, wag i nmetryk\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    ###############\n",
    "    # callback kontrolujący spadek błędu na datasecie validacyjnym\n",
    "    # i zatrzymujący uczenie jeśli się nie poprawi przez ileśtam epok\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    min_delta=0.0001,\n",
    "                                                    patience=5)\n",
    "    \n",
    "    ############### ZADANIE ################\n",
    "    # callback liczący f1-score\n",
    "    \n",
    "    # zwracamy listę callbacków\n",
    "    return tensorboard_callback, es_callback, f1_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback, es_callback = createCallbacks(modelSpam, \"spam_emb_128_lstm_128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSpam.fit(\n",
    "    x=sequences_matrix,\n",
    "    y=y_train,\n",
    "    batch_size=128,\n",
    "    epochs=40,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyznaczenie jakości na danych testowych\n",
    "res = modelSpam.evaluate(test_sequences_matrix,y_test, verbose=0)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(res[0],res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raport klasyfikacji\n",
    "y_pred = modelSpam.predict(test_sequences_matrix)\n",
    "y_pred = (y_pred>0.00014).astype(np.int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tworzymy wykres ROC - Receiver Operating Characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyznaczamy predykcję\n",
    "y_pred = modelSpam.predict(test_sequences_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liczymy auc i roc\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='orange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='white', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie: Callback f1-score\n",
    "Należy dodać do callbacków liczenie f1-score na zbiorze testowym co epokę."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja Newsów\n",
    "Należy wybrać kilka kategorii ze zbioru newsów i przeprowadzić klasyfikację tekstu z wykorzystaniem rekurencyjnych sieci neuronowych.\\\n",
    "\\\n",
    "Do wyboru są klasy:\\\n",
    "['alt.atheism', 'comp.graphics',\n",
    "'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "'comp.windows.x', 'misc.forsale', 'rec.autos',\n",
    "'rec.motorcycles', 'rec.sport.baseball',\n",
    "'rec.sport.hockey', 'sci.crypt', 'sci.electronics',\n",
    "'sci.med', 'sci.space', 'soc.religion.christian',\n",
    "'talk.politics.guns', 'talk.politics.mideast',\n",
    "'talk.politics.misc', 'talk.religion.misc']\\\n",
    "\\\n",
    "UWAGA: jeśli wybierzesz więcej niż dwie klasy to musisz zwrócić uwagę na to, że zadanie przestanie być klasyfikacją binarną. W stosunku do modelu z 5.3, będzie trzeba zmienić wyjście z sieci oraz funkcję kosztu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wybór kategorii\n",
    "categories = ['alt.atheism',\n",
    "              'comp.graphics',\n",
    "              'comp.sys.ibm.pc.hardware',\n",
    "              'comp.sys.mac.hardware',\n",
    "              'rec.sport.baseball',\n",
    "              'rec.sport.hockey',\n",
    "              'sci.med',\n",
    "              'sci.space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytywanie\n",
    "data_20 = fetch_20newsgroups(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data_20.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analiza danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_20.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyjścia\n",
    "unique_targets, unique_targets_cnts = np.unique(data_20.target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykreślamy ilościowy udział klas\n",
    "plt.bar(\n",
    "    x=data_20.target_names,\n",
    "    height=unique_targets_cnts\n",
    ")\n",
    "plt.xlabel('class name')\n",
    "plt.title('Number of samples per class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liczymy długości tekstów\n",
    "len(data_20.data[0].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_lenghts = np.array([len(txt.split(\" \")) for txt in data_20.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram długości tekstów\n",
    "plt.hist(txt_lenghts, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot długości tekstów, szukamy mediany\n",
    "plt.boxplot(txt_lenghts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mediana i kwantyle długości tekstów\n",
    "np.quantile(txt_lenghts, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90% wszystkich danych jest krótsza niż 500 słów i taki próg odcięcia wybierzemy. Zdecydowania mniejszość outlierów o długości tekstu sięgającej nawet 10 tysięcy słów spowoduje znaczne zwiększenie się wejścia do sieci. Skupimy się więc na zdecydowanej większości danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rzucamy dane na numpy array\n",
    "x = np.array(data_20.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy filtr odcinający teksty dłuższe niż 500 słów\n",
    "txt_cut_filter = txt_lenghts < 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrujemy dane wejściowe\n",
    "x = x[txt_cut_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrujemy wyjścia\n",
    "y = data_20.target[txt_cut_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzamy czy ilość się zgadza\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dla upewnienia się\n",
    "# boxplot długości tekstów po odcięciu\n",
    "plt.boxplot(txt_lenghts[txt_cut_filter])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram długości tekstów\n",
    "plt.hist(txt_lenghts[txt_cut_filter], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encodding wyjść"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = OneHotEncoder(sparse=False).fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20.target[txt_cut_filter][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### podział na trening i test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dzielimy na trening i test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizacja tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maksymalna ilość słów w słownika\n",
    "max_words = 1000\n",
    "# maksymalna długość wektora słów (zdania)\n",
    "max_len = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obiekt Tokenizatora, czyli konwertera słów na indeksy\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "\n",
    "# trenujemy tokenizator na danych treningowych\n",
    "tok.fit_on_texts(x_train)\n",
    "\n",
    "# konwersja textu na wektory\n",
    "sequences = tok.texts_to_sequences(x_train)\n",
    "\n",
    "# utworzenie macierzy sekwencji z paddingami\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "\n",
    "# dane testowe\n",
    "test_sequences = tok.texts_to_sequences(x_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequences[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequences_matrix[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "Należy uzupełnić oraz wykonać eksperyment.\n",
    "- modelu oraz kompilacja\n",
    "- wykonanie treningu\n",
    "- przeprowadzenie walidacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybryda cnn+rnn: Rozpoznawanie ciągu cyfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytujemy i podglądamy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.gray()\n",
    "plt.matshow(x_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names, class_counts = np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ile jest zdjęć z danej klasy\n",
    "# wykreślamy ilościowy udział klas\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(\n",
    "    x=class_names,\n",
    "    height=class_counts\n",
    ")\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('count')\n",
    "plt.title('Number of digits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tworzymy generator ciągów cyfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklejenie dwóch zdjęć ze sobą\n",
    "img1 = x_train[0]\n",
    "img2 = x_train[1]\n",
    "twoAtOne = np.concatenate((img1, img2), axis=1)\n",
    "print(\"labels: \", y_train[0], y_train[1])\n",
    "plt.gray()\n",
    "plt.matshow(twoAtOne)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklejenie dwóch zdjęć ze sobą\n",
    "img2 = x_train[4]\n",
    "twoAtOne = np.concatenate((twoAtOne, img2), axis=1)\n",
    "plt.gray()\n",
    "plt.matshow(twoAtOne)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konwersja labelek na onehoty\n",
    "# shape specjalnie jest trójwymiarowy, aby móc sklejać te wektory w pionie\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_train_onehot = onehot_encoder.fit_transform(\n",
    "    y_train.reshape(y_train.shape[0], 1)\n",
    ").reshape(y_train.shape[0],1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklejenie dwóch ze sobą, aby móc traktować to jako jeden target\n",
    "tmp_target = np.concatenate((y_train_onehot[0], y_train_onehot[1]))\n",
    "tmp_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# budujemy funkcję generującą zestaw losowo połączonych cyfr w ciągi o zadanej długości\n",
    "def images_vec_creator(x, y, vec_len, samples_num):\n",
    "    \"\"\"\n",
    "    :param x: images\n",
    "    :param y: labels, encoded, 3-dims [samples, 1, classes]\n",
    "    :param vec_len: length of concatenated images\n",
    "    :param samples_num: amount of randomly generated samples\n",
    "    \"\"\"\n",
    "    imgsNum = x.shape[0]\n",
    "    xList = []\n",
    "    yList = []\n",
    "    for i in range(samples_num):\n",
    "        # losujemy indeks pierwszego zdjęcia i labelki\n",
    "        tmpImgNum = random.randint(0, imgsNum-1)\n",
    "        tmpConcImgs = x[tmpImgNum]\n",
    "        tmpLabels = y[tmpImgNum]\n",
    "        for j in range(vec_len-1):\n",
    "            # losuejmy indeksy reszty\n",
    "            tmpImgNum = random.randint(0, imgsNum-1)\n",
    "            tmpConcImgs = np.concatenate((tmpConcImgs, x[tmpImgNum]), axis=1)\n",
    "            tmpLabels = np.concatenate((tmpLabels, y[tmpImgNum]))\n",
    "        # doklejamy do listy danych\n",
    "        xList.append(tmpConcImgs)\n",
    "        yList.append(tmpLabels)\n",
    "    # zamiana na numpajowe wektory\n",
    "    xData = np.array(xList)\n",
    "    yData = np.array(yList)\n",
    "    # liczymy wymiary danych\n",
    "    x_H = x.shape[1]\n",
    "    x_W = int(x.shape[2]*vec_len)\n",
    "    # zwrotka z normalizacją\n",
    "    return xData/255, yData, x_H, x_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generujemy dane treningowe\n",
    "vec_len = 4\n",
    "train_vecs_num = 10000\n",
    "x_train_vecs, y_train_vecs, x_H, x_W = images_vec_creator(x_train, y_train_onehot, vec_len, train_vecs_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podglądamy co to się narobiło\n",
    "tmp_idx=123\n",
    "print(\"target one :\\n\", y_train_vecs[tmp_idx])\n",
    "print(\"\\nlabels: \", onehot_encoder.inverse_transform(y_train_vecs[tmp_idx]).ravel())\n",
    "plt.gray()\n",
    "plt.matshow(x_train_vecs[tmp_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodanie wymiaru głóębi kanałów, sieć takowego potrzebuje\n",
    "print(f\"Przed: {x_train_vecs.shape}\")\n",
    "x_train_vecs = x_train_vecs.reshape(-1, x_H, x_W, 1)\n",
    "print(f\"Po: {x_train_vecs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzymy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pusty sekwencyjny\n",
    "model = tf.keras.Sequential()\n",
    "# ficzer ekstraktory\n",
    "model.add(layers.Conv2D(filters=4, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", input_shape=(x_H, x_W, 1), data_format=\"channels_last\"))\n",
    "model.add(layers.Conv2D(filters=8, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", data_format=\"channels_last\"))\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", data_format=\"channels_last\"))\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", data_format=\"channels_last\"))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", data_format=\"channels_last\"))\n",
    "model.add(layers.Dropout(0.4))\n",
    "# tworzymy sekwencje dla rnn'ów\n",
    "model.add(layers.Reshape((vec_len, 64)))\n",
    "model.add(layers.LSTM(128, return_sequences=True))\n",
    "model.add(layers.LSTM(64, return_sequences=True))\n",
    "# wyjście\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kompilacja\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=['categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodajemy zapisywanie logów do tensorboard'a\n",
    "# katalog nazywa się jak model wraz z czasem utworzenia\n",
    "log_dir = \"logs\\\\mnist_vecs\\\\4_digits_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "###############\n",
    "# główny callback odnoszący się do samego modelu, wag i nmetryk\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "###############\n",
    "# callback kontrolujący spadek błędu na datasecie validacyjnym\n",
    "# i zatrzymujący uczenie jeśli się nie poprawi przez ileśtam epok\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trening\n",
    "history = model.fit(\n",
    "    x_train_vecs,\n",
    "    y_train_vecs,\n",
    "    batch_size = 200,\n",
    "    epochs = 100,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        tensorboard_callback,\n",
    "        es_callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(20,20))\n",
    "ax1.plot(history.history['categorical_accuracy'])\n",
    "ax1.plot(history.history['val_categorical_accuracy'])\n",
    "ax1.legend([\"train\",\"validation\"])\n",
    "ax1.set_title(\"categorical_accuracy\")\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.legend([\"train\",\"validation\"])\n",
    "ax2.set_title(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przygotowujemy targety\n",
    "y_test_onehot = onehot_encoder.transform(\n",
    "    y_test.reshape(y_test.shape[0], 1)\n",
    ").reshape(y_test.shape[0],1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy dane\n",
    "test_vecs_num = 10000\n",
    "x_test_vecs, y_test_vecs, x_H, x_W = images_vec_creator(\n",
    "    x_test, y_test_onehot, vec_len, test_vecs_num)\n",
    "# korekta wymiarów danych\n",
    "x_test_vecs = x_test_vecs.reshape(-1, x_H, x_W, 1)\n",
    "# podglądamy co to się narobiło\n",
    "tmp_idx=123\n",
    "print(\"target one :\\n\", y_test_vecs[tmp_idx])\n",
    "print(\"\\nlabels: \", onehot_encoder.inverse_transform(y_test_vecs[tmp_idx]).ravel())\n",
    "plt.gray()\n",
    "plt.matshow(x_test_vecs[tmp_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# szybka ewaluacja\n",
    "eval_res = model.evaluate(x_test_vecs, y_test_vecs)\n",
    "eval_names = model.metrics_names\n",
    "print(f\"{eval_names[0]}: {eval_res[0]}\")\n",
    "print(f\"{eval_names[1]}: {eval_res[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzenie kilku pierwszych ciągów testowych\n",
    "testShowNum = 5\n",
    "# wyznaczenie wyjść\n",
    "y_pred_vecs = model.predict(x_test_vecs[:testShowNum])\n",
    "plt.gray()\n",
    "f, axis = plt.subplots(testShowNum, sharex=False, sharey=False, figsize=(20, 30))\n",
    "for i in range(testShowNum):\n",
    "    tmpIdx = i\n",
    "    axis[i].matshow(x_test_vecs[tmpIdx].reshape(x_H,x_W))\n",
    "    tmpTitle = \\\n",
    "        \"Real: \" + \\\n",
    "        np.array2string(onehot_encoder.inverse_transform(y_test_vecs[tmpIdx]).ravel()) + \\\n",
    "        \" | Pred: \" + \\\n",
    "        np.array2string(onehot_encoder.inverse_transform(y_pred_vecs[tmpIdx]).ravel())\n",
    "    axis[i].title.set_text(tmpTitle)\n",
    "    axis[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie: Sprawdzenie przy jakiej długości ciągów cyfr skuteczność klasyfikatora drastycznie spadnie.\n",
    "Należy:\n",
    "- wykonać szereg eksperymentów z różnymi długościami ciągów cyfr na jednym obrazie\n",
    "- zarejestrować wyniki dla każdego eksperymentu\n",
    "- zestawić i przeanalizować wyniki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dodatkowe materiały\n",
    "[tensorflow time series](https://www.tensorflow.org/tutorials/structured_data/time_series)\\\n",
    "[M4 forecasting](https://www.kaggle.com/yogesh94/m4-forecasting-competition-dataset?select=m4_info.csv)\\\n",
    "[ROC&AUC](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py)\\\n",
    "[ROC&AUC understanding](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "1118px",
    "left": "171px",
    "top": "118.778px",
    "width": "339px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
